{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Satisfaction\n",
    "https://www.kaggle.com/c/santander-customer-satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploratory analysis\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                   0                        0   \n",
       "1   3     2     34                   0                        0   \n",
       "2   4     2     23                   0                        0   \n",
       "3   8     2     37                   0                      195   \n",
       "4  10     2     39                   0                        0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                      195                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
       "0                        0                        0   ...     \n",
       "1                        0                        0   ...     \n",
       "2                        0                        0   ...     \n",
       "3                        0                        0   ...     \n",
       "4                        0                        0   ...     \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                        0                        0                       0   \n",
       "1                        0                        0                       0   \n",
       "2                        0                        0                       0   \n",
       "3                        0                        0                       0   \n",
       "4                        0                        0                       0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                       0                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                       0                       0   39205.170000       0  \n",
       "1                       0                       0   49278.030000       0  \n",
       "2                       0                       0   67333.770000       0  \n",
       "3                       0                       0   64007.970000       0  \n",
       "4                       0                       0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75813</th>\n",
       "      <td>151831</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40243.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75814</th>\n",
       "      <td>151832</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146961.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75815</th>\n",
       "      <td>151833</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167299.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75816</th>\n",
       "      <td>151834</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75817</th>\n",
       "      <td>151837</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "75813  151831     2     23                   0                        0   \n",
       "75814  151832     2     26                   0                        0   \n",
       "75815  151833     2     24                   0                        0   \n",
       "75816  151834     2     40                   0                        0   \n",
       "75817  151837     2     23                   0                        0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       imp_op_var40_efect_ult3      ...        saldo_medio_var29_ult3  \\\n",
       "75813                        0      ...                             0   \n",
       "75814                        0      ...                             0   \n",
       "75815                        0      ...                             0   \n",
       "75816                        0      ...                             0   \n",
       "75817                        0      ...                             0   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "75813                       0                       0   \n",
       "75814                       0                       0   \n",
       "75815                       0                       0   \n",
       "75816                       0                       0   \n",
       "75817                       0                       0   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  \n",
       "75813                       0                       0   40243.200000  \n",
       "75814                       0                       0  146961.300000  \n",
       "75815                       0                       0  167299.770000  \n",
       "75816                       0                       0  117310.979016  \n",
       "75817                       0                       0  117310.979016  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>117235.809430</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>182664.598503</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5163.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67870.612500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106409.160000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118756.252500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>22034738.760000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3      ...       \\\n",
       "count             76020.000000             76020.000000      ...        \n",
       "mean                  0.412946                 0.567352      ...        \n",
       "std                  30.604864                36.513513      ...        \n",
       "min                   0.000000                 0.000000      ...        \n",
       "25%                   0.000000                 0.000000      ...        \n",
       "50%                   0.000000                 0.000000      ...        \n",
       "75%                   0.000000                 0.000000      ...        \n",
       "max                6600.000000              6600.000000      ...        \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3            var38  \\\n",
       "count            76020.000000            76020.000000     76020.000000   \n",
       "mean                76.026165               56.614351    117235.809430   \n",
       "std               4040.337842             2852.579397    182664.598503   \n",
       "min                  0.000000                0.000000      5163.750000   \n",
       "25%                  0.000000                0.000000     67870.612500   \n",
       "50%                  0.000000                0.000000    106409.160000   \n",
       "75%                  0.000000                0.000000    118756.252500   \n",
       "max             681462.900000           397884.300000  22034738.760000   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'seaborn-darkgrid', u'seaborn-notebook', u'classic', u'seaborn-ticks', u'grayscale', u'bmh', u'seaborn-talk', u'dark_background', u'ggplot', u'fivethirtyeight', u'seaborn-colorblind', u'seaborn-deep', u'seaborn-whitegrid', u'seaborn-bright', u'seaborn-poster', u'seaborn-muted', u'seaborn-paper', u'seaborn-white', u'seaborn-pastel', u'seaborn-dark', u'seaborn-dark-palette']\n"
     ]
    }
   ],
   "source": [
    "print plt.style.available\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3008"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['TARGET']==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEECAYAAAA/L9PCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117ed6990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# var15 is AGE\n",
    "_ = train['var15'].hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# under 23 do not complain\n",
    "print len(train['TARGET'][train.var15<23])\n",
    "print sum(train['TARGET'][train.var15<23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use for spltting up combined train+test data, recording predictions\n",
    "labels = train['TARGET'].values\n",
    "df_train = train.drop(['TARGET'], axis=1)\n",
    "df_test = test.copy()\n",
    "id_test = test['ID']\n",
    "piv_train = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a DataFrame with train+test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "# Removing id\n",
    "# we can also remove id later\n",
    "df_all = df_all.drop(['ID'], axis=1)\n",
    "#(df_all.isnull().sum() / df_all.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count number of zeros\n",
    "df_all['n0'] = (df_all==0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filling nan\n",
    "df_all = df_all.fillna(-1)\n",
    "df_all_copy = df_all.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### var38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAEECAYAAAAyB950AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h9ARCm9INVyvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118d70590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at most important feature\n",
    "plt.hist(np.log(df_all['var38']), bins=50)\n",
    "plt.gcf().set_size_inches(9,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "2. Feature engineering\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAECCAYAAADgq+1UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c8b0210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at distribution of number of zeros per row\n",
    "plt.hist(df_all['n0'], bins=100)\n",
    "plt.gcf().set_size_inches(9,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: PCA reduced sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844458652792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.62662397,  0.14847085,  0.06936383])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3, copy=True, whiten=False)\n",
    "\n",
    "# fit the data\n",
    "pca.fit(df_all)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print sum(pca.explained_variance_ratio_)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69713134.35410738,  15506616.87953989,   7222578.09718822],\n",
       "       [ 69713135.75172846,  15506616.86019383,   7222578.07762365],\n",
       "       [ 69713134.33267833,  15506616.83488744,   7222578.05676919],\n",
       "       [ 69713134.33409454,  15506616.83951956,   7222578.06029954],\n",
       "       [ 69713131.96602239,  15506614.72698293,   7222574.84303513]])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce the data with pca\n",
    "df_pca = pca.transform(df_all)\n",
    "df_pca[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>n0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>356</td>\n",
       "      <td>69713134.354107</td>\n",
       "      <td>15506616.879540</td>\n",
       "      <td>7222578.097188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>330</td>\n",
       "      <td>69713135.751728</td>\n",
       "      <td>15506616.860194</td>\n",
       "      <td>7222578.077624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>341</td>\n",
       "      <td>69713134.332678</td>\n",
       "      <td>15506616.834887</td>\n",
       "      <td>7222578.056769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>310</td>\n",
       "      <td>69713134.334095</td>\n",
       "      <td>15506616.839520</td>\n",
       "      <td>7222578.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>320</td>\n",
       "      <td>69713131.966022</td>\n",
       "      <td>15506614.726983</td>\n",
       "      <td>7222574.843035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     23                   0                        0   \n",
       "1     2     34                   0                        0   \n",
       "2     2     23                   0                        0   \n",
       "3     2     37                   0                      195   \n",
       "4     2     39                   0                        0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                      195                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  \\\n",
       "0                        0                        0                  0   \n",
       "1                        0                        0                  0   \n",
       "2                        0                        0                  0   \n",
       "3                        0                        0                  0   \n",
       "4                        0                        0                  0   \n",
       "\n",
       "        ...        saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0       ...                             0                        0   \n",
       "1       ...                             0                        0   \n",
       "2       ...                             0                        0   \n",
       "3       ...                             0                        0   \n",
       "4       ...                             0                        0   \n",
       "\n",
       "   saldo_medio_var44_hace3  saldo_medio_var44_ult1  saldo_medio_var44_ult3  \\\n",
       "0                        0                       0                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "\n",
       "           var38   n0             pca1             pca2            pca3  \n",
       "0   39205.170000  356  69713134.354107  15506616.879540  7222578.097188  \n",
       "1   49278.030000  330  69713135.751728  15506616.860194  7222578.077624  \n",
       "2   67333.770000  341  69713134.332678  15506616.834887  7222578.056769  \n",
       "3   64007.970000  310  69713134.334095  15506616.839520  7222578.060300  \n",
       "4  117310.979016  320  69713131.966022  15506614.726983  7222574.843035  \n",
       "\n",
       "[5 rows x 373 columns]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['pca1'] = df_pca[:,0]\n",
    "df_all['pca2'] = df_pca[:,1]\n",
    "df_all['pca3'] = df_pca[:,2]\n",
    "#df_all['pca4'] = df_pca[:,3]\n",
    "#df_all['pca5'] = df_pca[:,4]\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "# look at important features: engineered 'n0', 'pca1', 'pca2', 'pca3', 'pca4', 'pca5'\n",
    "features = ['var3', 'var15', 'imp_ent_var16_ult1', 'imp_op_var39_comer_ult3', \n",
    "'imp_op_var41_comer_ult1', 'imp_op_var41_comer_ult3', 'imp_op_var41_efect_ult1', \n",
    "'imp_op_var41_efect_ult3', 'imp_op_var41_ult1', 'imp_op_var39_ult1', 'ind_var8_0', \n",
    "'ind_var30_0', 'ind_var30', 'num_op_var41_hace2', 'num_op_var41_ult3', \n",
    "'num_var37_med_ult2', 'saldo_var5', 'saldo_var8', 'saldo_var26', 'saldo_var30', \n",
    "'saldo_var37', 'saldo_var42', 'imp_var43_emit_ult1', 'imp_trans_var37_ult1', \n",
    "'num_var22_hace2', 'num_var22_hace3', 'num_var22_ult1', 'num_var22_ult3',\n",
    "'num_med_var45_ult3', 'num_meses_var5_ult3', 'num_meses_var39_vig_ult3',\n",
    "'num_op_var39_comer_ult1', 'num_op_var41_efect_ult3', 'num_op_var39_efect_ult1',\n",
    "'num_var43_recib_ult1', 'num_var45_hace2', 'num_var45_hace3', 'num_var45_ult1',\n",
    "'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3', \n",
    "'saldo_medio_var5_ult1', 'saldo_medio_var5_ult3', 'saldo_medio_var8_hace2',\n",
    "'saldo_medio_var8_ult1', 'saldo_medio_var8_ult3', 'saldo_medio_var12_ult3',\n",
    "'saldo_medio_var13_corto_hace2', 'var38', 'n0', 'pca1', 'pca2', 'pca3']\n",
    "print len(features)\n",
    "df_sel = df_all[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting train and test\n",
    "vals = df_all.values\n",
    "X = vals[:piv_train]\n",
    "X_test_submit = vals[piv_train:]\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test with normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "from sklearn.preprocessing import normalize\n",
    "df_norm = normalize(df_sel, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Splitting train and test\n",
    "vals = df_norm\n",
    "X = vals[:piv_train]\n",
    "X_test_submit = vals[piv_train:]\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020,)\n",
      "(76020, 53)\n",
      "(75818, 53)\n"
     ]
    }
   ],
   "source": [
    "print y.shape\n",
    "print X.shape\n",
    "print X_test_submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Split train data further into train/validation/test sets\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** convert labels to vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020,)\n"
     ]
    }
   ],
   "source": [
    "y_copy = y.copy()\n",
    "print y_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reformat labels as vector\n",
    "def reformat(labels, num_labels=12):\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)  # convert label to vector\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213451, 12)\n"
     ]
    }
   ],
   "source": [
    "## variable for new label vectors\n",
    "y_vec = reformat(y_copy)\n",
    "print y_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## keep copy of X_test_submit\n",
    "X_test_copy = X_test_submit.copy()\n",
    "#X_test_submit = X_test_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert test submission dtype\n",
    "X_test_submit = X_test_norm.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## split normalized data into train and test\n",
    "X_tv, X_test, y_tv, y_test = cross_validation.train_test_split(X_norm.astype('float32'), \\\n",
    "                                                               y_vec.astype('float32'), test_size=.05, random_state=205)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = cross_validation.train_test_split(X_tv, y_tv, \\\n",
    "                                                                       test_size=.05, random_state=71511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## split into train and validation\n",
    "## use X,y for full training data\n",
    "X_train, X_valid, y_train, y_valid = cross_validation.train_test_split(X, y, test_size=.1, \n",
    "                                                                       stratify=y, \n",
    "                                                                       random_state=429)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "\n",
    "## Make scorer\n",
    "auc_scorer = metrics.make_scorer(metrics.roc_auc_score, greater_is_better=True)\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, greater_is_better=True, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Random forest\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create cv search objec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "'''\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \\\n",
    "                            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \\\n",
    "                            max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, \\\n",
    "                            n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "'''\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "est = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=427)\n",
    "parameters = {'max_depth': [6, None]\n",
    "             }\n",
    "reg = grid_search.GridSearchCV(est, parameters, scoring=auc_scorer, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i-a. Extra Trees\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: extremely randomized forests\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "est = ExtraTreesClassifier(n_estimators=128,max_features= 30,criterion= 'entropy',\n",
    "                            min_samples_split= 2,max_depth= 30, min_samples_leaf= 2, \n",
    "                            n_jobs = -1, random_state=429)    \n",
    "parameters = {'max_depth': [30, None]\n",
    "             }\n",
    "reg = grid_search.GridSearchCV(est, parameters, scoring=auc_scorer, cv=3)\n",
    "\n",
    "# train the estimator directly on data\n",
    "# est.fit(X, y)\n",
    "# print est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. SVM\n",
    "http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# Setup a Classifier\n",
    "clf = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, \\\n",
    "                  shrinking=True, probability=False, tol=0.001, cache_size=200, \\\n",
    "                  class_weight='balanced', verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)\n",
    "# tune parameter with at least 3 settings\n",
    "parameters = {'C': (1.0, 0.2),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PCA reduced data\n",
    "X_reduced = pca.transform(X)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. XGBoost\n",
    "https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Classifier\n",
    "# try using... objective: multi:softprob, rank:pairwise\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "ratio = float(np.sum(y == 1)) / np.sum(y==0)\n",
    "est = XGBClassifier(max_depth=8, learning_rate=0.1, n_estimators=320,\n",
    "                    objective='binary:logistic', subsample=0.8, colsample_bytree=0.8, \n",
    "                    min_child_weight=3, scale_pos_weight=ratio, seed=429)                  \n",
    "\n",
    "param = {\n",
    "    'objective':'multi:softprob',                    \n",
    "    'max_depth':6, \n",
    "    'learning_rate':0.25, \n",
    "    'n_estimators':43,                 \n",
    "    'subsample':0.6, \n",
    "    'colsample_bytree':0.6,\n",
    "    'num_class' :12\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_set = [(X_train,y_train), (X_valid,y_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until validation_1 error hasn't decreased in 50 rounds.\n",
      "[0]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[1]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[2]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[3]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[4]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[5]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[6]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[7]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[8]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[9]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[10]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[11]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[12]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[13]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[14]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[15]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[16]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[17]\tvalidation_0-auc:0.716327\tvalidation_1-auc:0.701622\n",
      "[18]\tvalidation_0-auc:0.716324\tvalidation_1-auc:0.701595\n",
      "[19]\tvalidation_0-auc:0.716324\tvalidation_1-auc:0.701595\n",
      "[20]\tvalidation_0-auc:0.716485\tvalidation_1-auc:0.701530\n",
      "[21]\tvalidation_0-auc:0.716485\tvalidation_1-auc:0.701530\n",
      "[22]\tvalidation_0-auc:0.716347\tvalidation_1-auc:0.701125\n",
      "[23]\tvalidation_0-auc:0.716347\tvalidation_1-auc:0.701125\n",
      "[24]\tvalidation_0-auc:0.720785\tvalidation_1-auc:0.705701\n",
      "[25]\tvalidation_0-auc:0.721033\tvalidation_1-auc:0.706534\n",
      "[26]\tvalidation_0-auc:0.722677\tvalidation_1-auc:0.707443\n",
      "[27]\tvalidation_0-auc:0.723328\tvalidation_1-auc:0.708339\n",
      "[28]\tvalidation_0-auc:0.723314\tvalidation_1-auc:0.708271\n",
      "[29]\tvalidation_0-auc:0.723301\tvalidation_1-auc:0.708269\n",
      "[30]\tvalidation_0-auc:0.723440\tvalidation_1-auc:0.708236\n",
      "[31]\tvalidation_0-auc:0.734962\tvalidation_1-auc:0.713945\n",
      "[32]\tvalidation_0-auc:0.736221\tvalidation_1-auc:0.713956\n",
      "[33]\tvalidation_0-auc:0.736227\tvalidation_1-auc:0.714015\n",
      "[34]\tvalidation_0-auc:0.736238\tvalidation_1-auc:0.714034\n",
      "[35]\tvalidation_0-auc:0.738414\tvalidation_1-auc:0.715682\n",
      "[36]\tvalidation_0-auc:0.738786\tvalidation_1-auc:0.716234\n",
      "[37]\tvalidation_0-auc:0.744764\tvalidation_1-auc:0.717241\n",
      "[38]\tvalidation_0-auc:0.746185\tvalidation_1-auc:0.717598\n",
      "[39]\tvalidation_0-auc:0.746681\tvalidation_1-auc:0.717464\n",
      "[40]\tvalidation_0-auc:0.751129\tvalidation_1-auc:0.718893\n",
      "[41]\tvalidation_0-auc:0.808685\tvalidation_1-auc:0.792223\n",
      "[42]\tvalidation_0-auc:0.806855\tvalidation_1-auc:0.790597\n",
      "[43]\tvalidation_0-auc:0.806783\tvalidation_1-auc:0.790010\n",
      "[44]\tvalidation_0-auc:0.811376\tvalidation_1-auc:0.795017\n",
      "[45]\tvalidation_0-auc:0.813740\tvalidation_1-auc:0.802805\n",
      "[46]\tvalidation_0-auc:0.816700\tvalidation_1-auc:0.807817\n",
      "[47]\tvalidation_0-auc:0.821776\tvalidation_1-auc:0.810252\n",
      "[48]\tvalidation_0-auc:0.823560\tvalidation_1-auc:0.813911\n",
      "[49]\tvalidation_0-auc:0.823206\tvalidation_1-auc:0.812426\n",
      "[50]\tvalidation_0-auc:0.825383\tvalidation_1-auc:0.813700\n",
      "[51]\tvalidation_0-auc:0.826291\tvalidation_1-auc:0.814774\n",
      "[52]\tvalidation_0-auc:0.827720\tvalidation_1-auc:0.817269\n",
      "[53]\tvalidation_0-auc:0.827747\tvalidation_1-auc:0.817206\n",
      "[54]\tvalidation_0-auc:0.829981\tvalidation_1-auc:0.819796\n",
      "[55]\tvalidation_0-auc:0.832234\tvalidation_1-auc:0.821563\n",
      "[56]\tvalidation_0-auc:0.833954\tvalidation_1-auc:0.823655\n",
      "[57]\tvalidation_0-auc:0.834570\tvalidation_1-auc:0.824453\n",
      "[58]\tvalidation_0-auc:0.836001\tvalidation_1-auc:0.825392\n",
      "[59]\tvalidation_0-auc:0.837066\tvalidation_1-auc:0.826321\n",
      "[60]\tvalidation_0-auc:0.838206\tvalidation_1-auc:0.827251\n",
      "[61]\tvalidation_0-auc:0.839319\tvalidation_1-auc:0.828110\n",
      "[62]\tvalidation_0-auc:0.839416\tvalidation_1-auc:0.827923\n",
      "[63]\tvalidation_0-auc:0.839568\tvalidation_1-auc:0.827594\n",
      "[64]\tvalidation_0-auc:0.839866\tvalidation_1-auc:0.827802\n",
      "[65]\tvalidation_0-auc:0.840232\tvalidation_1-auc:0.828388\n",
      "[66]\tvalidation_0-auc:0.840646\tvalidation_1-auc:0.828898\n",
      "[67]\tvalidation_0-auc:0.841446\tvalidation_1-auc:0.829388\n",
      "[68]\tvalidation_0-auc:0.841475\tvalidation_1-auc:0.829686\n",
      "[69]\tvalidation_0-auc:0.842414\tvalidation_1-auc:0.830059\n",
      "[70]\tvalidation_0-auc:0.842641\tvalidation_1-auc:0.830629\n",
      "[71]\tvalidation_0-auc:0.843039\tvalidation_1-auc:0.830977\n",
      "[72]\tvalidation_0-auc:0.843375\tvalidation_1-auc:0.831773\n",
      "[73]\tvalidation_0-auc:0.843647\tvalidation_1-auc:0.832107\n",
      "[74]\tvalidation_0-auc:0.844110\tvalidation_1-auc:0.832383\n",
      "[75]\tvalidation_0-auc:0.844339\tvalidation_1-auc:0.832364\n",
      "[76]\tvalidation_0-auc:0.844706\tvalidation_1-auc:0.832369\n",
      "[77]\tvalidation_0-auc:0.844852\tvalidation_1-auc:0.832495\n",
      "[78]\tvalidation_0-auc:0.845196\tvalidation_1-auc:0.832637\n",
      "[79]\tvalidation_0-auc:0.845875\tvalidation_1-auc:0.833004\n",
      "[80]\tvalidation_0-auc:0.846213\tvalidation_1-auc:0.832799\n",
      "[81]\tvalidation_0-auc:0.846414\tvalidation_1-auc:0.833011\n",
      "[82]\tvalidation_0-auc:0.846554\tvalidation_1-auc:0.833240\n",
      "[83]\tvalidation_0-auc:0.846838\tvalidation_1-auc:0.833528\n",
      "[84]\tvalidation_0-auc:0.847093\tvalidation_1-auc:0.833883\n",
      "[85]\tvalidation_0-auc:0.847178\tvalidation_1-auc:0.834094\n",
      "[86]\tvalidation_0-auc:0.847383\tvalidation_1-auc:0.834425\n",
      "[87]\tvalidation_0-auc:0.847515\tvalidation_1-auc:0.834522\n",
      "[88]\tvalidation_0-auc:0.847714\tvalidation_1-auc:0.834665\n",
      "[89]\tvalidation_0-auc:0.847904\tvalidation_1-auc:0.834525\n",
      "[90]\tvalidation_0-auc:0.847985\tvalidation_1-auc:0.834642\n",
      "[91]\tvalidation_0-auc:0.848308\tvalidation_1-auc:0.835104\n",
      "[92]\tvalidation_0-auc:0.848605\tvalidation_1-auc:0.835320\n",
      "[93]\tvalidation_0-auc:0.848678\tvalidation_1-auc:0.835318\n",
      "[94]\tvalidation_0-auc:0.848798\tvalidation_1-auc:0.835292\n",
      "[95]\tvalidation_0-auc:0.849088\tvalidation_1-auc:0.835571\n",
      "[96]\tvalidation_0-auc:0.849204\tvalidation_1-auc:0.835450\n",
      "[97]\tvalidation_0-auc:0.849510\tvalidation_1-auc:0.835525\n",
      "[98]\tvalidation_0-auc:0.849692\tvalidation_1-auc:0.835592\n",
      "[99]\tvalidation_0-auc:0.849799\tvalidation_1-auc:0.835448\n",
      "[100]\tvalidation_0-auc:0.850088\tvalidation_1-auc:0.835369\n",
      "[101]\tvalidation_0-auc:0.850215\tvalidation_1-auc:0.835500\n",
      "[102]\tvalidation_0-auc:0.850444\tvalidation_1-auc:0.835521\n",
      "[103]\tvalidation_0-auc:0.850647\tvalidation_1-auc:0.835299\n",
      "[104]\tvalidation_0-auc:0.850774\tvalidation_1-auc:0.835467\n",
      "[105]\tvalidation_0-auc:0.850862\tvalidation_1-auc:0.835601\n",
      "[106]\tvalidation_0-auc:0.851088\tvalidation_1-auc:0.835521\n",
      "[107]\tvalidation_0-auc:0.851231\tvalidation_1-auc:0.835592\n",
      "[108]\tvalidation_0-auc:0.851397\tvalidation_1-auc:0.835803\n",
      "[109]\tvalidation_0-auc:0.851588\tvalidation_1-auc:0.835831\n",
      "[110]\tvalidation_0-auc:0.851795\tvalidation_1-auc:0.835922\n",
      "[111]\tvalidation_0-auc:0.851853\tvalidation_1-auc:0.835662\n",
      "[112]\tvalidation_0-auc:0.852003\tvalidation_1-auc:0.835628\n",
      "[113]\tvalidation_0-auc:0.852207\tvalidation_1-auc:0.835489\n",
      "[114]\tvalidation_0-auc:0.852324\tvalidation_1-auc:0.835545\n",
      "[115]\tvalidation_0-auc:0.852426\tvalidation_1-auc:0.835687\n",
      "[116]\tvalidation_0-auc:0.852560\tvalidation_1-auc:0.835841\n",
      "[117]\tvalidation_0-auc:0.852739\tvalidation_1-auc:0.835770\n",
      "[118]\tvalidation_0-auc:0.852889\tvalidation_1-auc:0.835914\n",
      "[119]\tvalidation_0-auc:0.853109\tvalidation_1-auc:0.836010\n",
      "[120]\tvalidation_0-auc:0.853438\tvalidation_1-auc:0.836211\n",
      "[121]\tvalidation_0-auc:0.853528\tvalidation_1-auc:0.836405\n",
      "[122]\tvalidation_0-auc:0.853690\tvalidation_1-auc:0.836372\n",
      "[123]\tvalidation_0-auc:0.853812\tvalidation_1-auc:0.836605\n",
      "[124]\tvalidation_0-auc:0.853946\tvalidation_1-auc:0.836657\n",
      "[125]\tvalidation_0-auc:0.854084\tvalidation_1-auc:0.836646\n",
      "[126]\tvalidation_0-auc:0.854223\tvalidation_1-auc:0.836701\n",
      "[127]\tvalidation_0-auc:0.854385\tvalidation_1-auc:0.836836\n",
      "[128]\tvalidation_0-auc:0.854532\tvalidation_1-auc:0.836837\n",
      "[129]\tvalidation_0-auc:0.854726\tvalidation_1-auc:0.836889\n",
      "[130]\tvalidation_0-auc:0.854850\tvalidation_1-auc:0.837044\n",
      "[131]\tvalidation_0-auc:0.854939\tvalidation_1-auc:0.836984\n",
      "[132]\tvalidation_0-auc:0.855147\tvalidation_1-auc:0.836790\n",
      "[133]\tvalidation_0-auc:0.855320\tvalidation_1-auc:0.836619\n",
      "[134]\tvalidation_0-auc:0.855502\tvalidation_1-auc:0.836868\n",
      "[135]\tvalidation_0-auc:0.855674\tvalidation_1-auc:0.836825\n",
      "[136]\tvalidation_0-auc:0.855803\tvalidation_1-auc:0.836750\n",
      "[137]\tvalidation_0-auc:0.855903\tvalidation_1-auc:0.836814\n",
      "[138]\tvalidation_0-auc:0.856113\tvalidation_1-auc:0.836872\n",
      "[139]\tvalidation_0-auc:0.856299\tvalidation_1-auc:0.837073\n",
      "[140]\tvalidation_0-auc:0.856407\tvalidation_1-auc:0.837020\n",
      "[141]\tvalidation_0-auc:0.856488\tvalidation_1-auc:0.837052\n",
      "[142]\tvalidation_0-auc:0.856642\tvalidation_1-auc:0.837020\n",
      "[143]\tvalidation_0-auc:0.856736\tvalidation_1-auc:0.837091\n",
      "[144]\tvalidation_0-auc:0.856758\tvalidation_1-auc:0.837089\n",
      "[145]\tvalidation_0-auc:0.856907\tvalidation_1-auc:0.836971\n",
      "[146]\tvalidation_0-auc:0.857014\tvalidation_1-auc:0.837128\n",
      "[147]\tvalidation_0-auc:0.857131\tvalidation_1-auc:0.836903\n",
      "[148]\tvalidation_0-auc:0.857317\tvalidation_1-auc:0.837015\n",
      "[149]\tvalidation_0-auc:0.857507\tvalidation_1-auc:0.837006\n",
      "[150]\tvalidation_0-auc:0.857627\tvalidation_1-auc:0.836907\n",
      "[151]\tvalidation_0-auc:0.857769\tvalidation_1-auc:0.836821\n",
      "[152]\tvalidation_0-auc:0.857870\tvalidation_1-auc:0.836746\n",
      "[153]\tvalidation_0-auc:0.857955\tvalidation_1-auc:0.836569\n",
      "[154]\tvalidation_0-auc:0.858049\tvalidation_1-auc:0.836513\n",
      "[155]\tvalidation_0-auc:0.858105\tvalidation_1-auc:0.836401\n",
      "[156]\tvalidation_0-auc:0.858268\tvalidation_1-auc:0.836440\n",
      "[157]\tvalidation_0-auc:0.858372\tvalidation_1-auc:0.836484\n",
      "[158]\tvalidation_0-auc:0.858561\tvalidation_1-auc:0.836238\n",
      "[159]\tvalidation_0-auc:0.858657\tvalidation_1-auc:0.836276\n",
      "[160]\tvalidation_0-auc:0.858761\tvalidation_1-auc:0.835965\n",
      "[161]\tvalidation_0-auc:0.858798\tvalidation_1-auc:0.836092\n",
      "[162]\tvalidation_0-auc:0.858902\tvalidation_1-auc:0.836204\n",
      "[163]\tvalidation_0-auc:0.859010\tvalidation_1-auc:0.836251\n",
      "[164]\tvalidation_0-auc:0.859140\tvalidation_1-auc:0.836327\n",
      "[165]\tvalidation_0-auc:0.859240\tvalidation_1-auc:0.836251\n",
      "[166]\tvalidation_0-auc:0.859397\tvalidation_1-auc:0.836164\n",
      "[167]\tvalidation_0-auc:0.859457\tvalidation_1-auc:0.836078\n",
      "[168]\tvalidation_0-auc:0.859610\tvalidation_1-auc:0.836009\n",
      "[169]\tvalidation_0-auc:0.859688\tvalidation_1-auc:0.836027\n",
      "[170]\tvalidation_0-auc:0.859890\tvalidation_1-auc:0.836150\n",
      "[171]\tvalidation_0-auc:0.860016\tvalidation_1-auc:0.836220\n",
      "[172]\tvalidation_0-auc:0.860174\tvalidation_1-auc:0.836186\n",
      "[173]\tvalidation_0-auc:0.860334\tvalidation_1-auc:0.836236\n",
      "[174]\tvalidation_0-auc:0.860431\tvalidation_1-auc:0.836155\n",
      "[175]\tvalidation_0-auc:0.860510\tvalidation_1-auc:0.836153\n",
      "[176]\tvalidation_0-auc:0.860672\tvalidation_1-auc:0.836126\n",
      "[177]\tvalidation_0-auc:0.860763\tvalidation_1-auc:0.835998\n",
      "[178]\tvalidation_0-auc:0.860923\tvalidation_1-auc:0.836154\n",
      "[179]\tvalidation_0-auc:0.861026\tvalidation_1-auc:0.836121\n",
      "[180]\tvalidation_0-auc:0.861122\tvalidation_1-auc:0.836309\n",
      "[181]\tvalidation_0-auc:0.861209\tvalidation_1-auc:0.836187\n",
      "[182]\tvalidation_0-auc:0.861299\tvalidation_1-auc:0.836336\n",
      "[183]\tvalidation_0-auc:0.861321\tvalidation_1-auc:0.836261\n",
      "[184]\tvalidation_0-auc:0.861428\tvalidation_1-auc:0.836393\n",
      "[185]\tvalidation_0-auc:0.861616\tvalidation_1-auc:0.836365\n",
      "[186]\tvalidation_0-auc:0.861701\tvalidation_1-auc:0.836342\n",
      "[187]\tvalidation_0-auc:0.861821\tvalidation_1-auc:0.836427\n",
      "[188]\tvalidation_0-auc:0.861913\tvalidation_1-auc:0.836357\n",
      "[189]\tvalidation_0-auc:0.861968\tvalidation_1-auc:0.836199\n",
      "[190]\tvalidation_0-auc:0.862067\tvalidation_1-auc:0.836094\n",
      "[191]\tvalidation_0-auc:0.862135\tvalidation_1-auc:0.836024\n",
      "[192]\tvalidation_0-auc:0.862190\tvalidation_1-auc:0.836129\n",
      "[193]\tvalidation_0-auc:0.862282\tvalidation_1-auc:0.836134\n",
      "[194]\tvalidation_0-auc:0.862392\tvalidation_1-auc:0.836240\n",
      "[195]\tvalidation_0-auc:0.862544\tvalidation_1-auc:0.836301\n",
      "[196]\tvalidation_0-auc:0.862634\tvalidation_1-auc:0.836285\n",
      "Stopping. Best iteration:\n",
      "[146]\tvalidation_0-auc:0.857014\tvalidation_1-auc:0.837128\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=3, missing=None, n_estimators=320, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=0.0411987070619, seed=429, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try using... eval_metric: mlogloss, merror, ndcg@n-, logloss, auc\n",
    "est.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds=50, eval_metric='auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model for later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('models/my_ext_2.pkl', 'wb') as f:\n",
    "    cPickle.dump(est, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
      "       min_child_weight=3, missing=nan, n_estimators=256, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=0.0411987070619, seed=415, silent=True,\n",
      "       subsample=1.0)\n"
     ]
    }
   ],
   "source": [
    "# load it again\n",
    "with open('models/my_xgb_2.pkl', 'rb') as f:\n",
    "    clf_loaded = cPickle.load(f)\n",
    "print clf_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign loaded model to \"est\"\n",
    "est = clf_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit with grid search\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=30, max_features=30, max_leaf_nodes=None,\n",
       "           min_samples_leaf=2, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=128, n_jobs=-1,\n",
       "           oob_score=False, random_state=429, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [30, None]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring=make_scorer(roc_auc_score), verbose=0)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit data with random forest\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=30, max_features=30, max_leaf_nodes=None,\n",
       "           min_samples_leaf=2, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=128, n_jobs=-1,\n",
       "           oob_score=False, random_state=429, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the best predictor\n",
    "est = reg.best_estimator_\n",
    "est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## predict classes\n",
    "ypred = est.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98     73012\n",
      "          1       0.99      0.06      0.11      3008\n",
      "\n",
      "avg / total       0.96      0.96      0.95     76020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the results, my_xgb_2\n",
    "print metrics.classification_report(y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96     73012\n",
      "          1       0.35      0.90      0.50      3008\n",
      "\n",
      "avg / total       0.97      0.93      0.94     76020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the results, my_rf_1\n",
    "print metrics.classification_report(y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904821346586\n"
     ]
    }
   ],
   "source": [
    "## ext, predict probabilities\n",
    "ypred = est.predict_proba(X)\n",
    "print metrics.roc_auc_score(y, ypred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860005361258\n"
     ]
    }
   ],
   "source": [
    "## xgb, predict probabilities\n",
    "ypred = est.predict_proba(X)\n",
    "print metrics.roc_auc_score(y, ypred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96753999461\n"
     ]
    }
   ],
   "source": [
    "## rf, predict probabilities\n",
    "ypred = est.predict_proba(X)\n",
    "print metrics.roc_auc_score(y, ypred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 373)\n",
      "(75818, 2)\n",
      "[[ 0.97531381  0.02468619]\n",
      " [ 0.97710959  0.02289041]\n",
      " [ 0.99168889  0.00831111]\n",
      " [ 0.9417563   0.0582437 ]\n",
      " [ 0.99005642  0.00994358]\n",
      " [ 0.87017838  0.12982162]\n",
      " [ 0.93541667  0.06458333]\n",
      " [ 0.89414334  0.10585666]\n",
      " [ 0.97353123  0.02646877]\n",
      " [ 0.953741    0.046259  ]\n",
      " [ 0.98681467  0.01318533]\n",
      " [ 0.98914652  0.01085348]]\n"
     ]
    }
   ],
   "source": [
    "## predict test, class probabilities\n",
    "ypred_submit = est.predict_proba(X_test_submit)\n",
    "print X_test_submit.shape\n",
    "print ypred_submit.shape\n",
    "print ypred_submit[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate submission: stack ids and targets together into dataframe\n",
    "'''\n",
    "# old version -- \n",
    "sub = pd.DataFrame(np.column_stack(id_test, ypred_submit[:,1])), columns=['ID', 'TARGET'])\n",
    "'''\n",
    "\n",
    "sub = pd.concat([id_test, pd.Series(ypred_submit[:,1], name='TARGET')], axis=1)\n",
    "\n",
    "# write dataframe to csv\n",
    "sub.to_csv('../submit/ext2_20160429.csv',index=False, float_format='%.16f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID          int64\n",
       "TARGET    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change pred for age (var15) < 23 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remember features that predict 0\n",
    "var15 = test['var15']\n",
    "saldo_medio_var5_hace2 = test['saldo_medio_var5_hace2']\n",
    "saldo_var33 = test['saldo_var33']\n",
    "var38 = test['var38']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97531381  0.02468619]\n",
      " [ 0.97710959  0.02289041]\n",
      " [ 0.99168889  0.00831111]\n",
      " [ 0.9417563   0.0582437 ]\n",
      " [ 0.99005642  0.00994358]\n",
      " [ 0.87017838  0.12982162]\n",
      " [ 0.93541667  0.        ]\n",
      " [ 0.89414334  0.10585666]]\n"
     ]
    }
   ],
   "source": [
    "# Under 23 year olds are always happy\n",
    "ypred_submit[list(var15.index[var15 < 23]), 1] = 0\n",
    "#ypred_submit[list(saldo_medio_var5_hace2.index[saldo_medio_var5_hace2 > 160000]), 1] = 0\n",
    "ypred_submit[list(saldo_var33.index[saldo_var33 > 0]), 1] = 0\n",
    "ypred_submit[list(var38.index[var38 > 3988596]), 1] = 0\n",
    "print ypred_submit[:8]\n",
    "# from the original R script\n",
    "#preds[NV>0]=0\n",
    "#preds[V21>7500]=0\n",
    "\n",
    "# write dataframe to csv\n",
    "sub = pd.concat([id_test, pd.Series(ypred_submit[:,1], name='TARGET')], axis=1)\n",
    "sub.to_csv('../submit/ext2_var15_20160429.csv',index=False, float_format='%.16f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Voting Classifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.33448022e-01,   6.65520288e-02],\n",
       "       [  9.62528953e-01,   3.74710348e-02],\n",
       "       [  9.99925745e-01,   7.42562042e-05],\n",
       "       [  9.99568772e-01,   4.31227818e-04],\n",
       "       [  9.98117258e-01,   1.88275319e-03],\n",
       "       [  8.86325098e-01,   1.13674911e-01],\n",
       "       [  9.61121901e-01,   3.88780951e-02],\n",
       "       [  8.96974891e-01,   1.03025138e-01],\n",
       "       [  9.71420058e-01,   2.85799215e-02],\n",
       "       [  9.89302377e-01,   1.06976180e-02]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict using a second model and average the results\n",
    "ypred_2 = est_2.predict_proba(X_test_submit)\n",
    "ypred_avg = (.2 * ypred_submit) + (.8 * ypred_2)\n",
    "ypred_avg[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "iv. Tensorflow\n",
    "----------\n",
    "\n",
    "> **1-2 hidden layers **<br>\n",
    "> steps 5001, L2 reg .001, hidden 1024, rate (.5, 1000, .8), Test accuracy: **58.78**%<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x500, keep .9, rate (.05 adagrad), Test accuracy: **58.78**%<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x300, keep 1., rate (.01 adagrad), Test accuracy: **58.17**%<br>\n",
    "\n",
    "> **1-2 hidden layers, init low w, b**<br>\n",
    "> steps 5001, L2 reg .0002, hidden 1024x500, keep 1., rate (.1 adagrad), Test accuracy: **58.78**%<br>\n",
    "\n",
    "> **3 hidden layers **<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x300x50, rate (.01 adagrad), Test accuracy: **58.17**%<br>\n",
    "\n",
    "> **PCA 40 dims **<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x300x50, rate (.01 adagrad), Test accuracy: **58.17**%<br>\n",
    "\n",
    "> **107 features (del 'first_browser') **<br>\n",
    "> steps 5001, L2 reg .0002, hidden 1024x300x50, rate (.1 adagrad), Test accuracy: **58.04**%<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev=0.1):\n",
    "  initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, constant=0.):\n",
    "  initial = tf.constant(constant, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Build graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192639, 316)\n",
      "float32\n",
      "(10139, 316)\n",
      "(10673, 316)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "(192639, 12)\n",
      "(10139, 12)\n",
      "(10673, 12)\n",
      "(62096, 316)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_train.dtype\n",
    "print X_valid.shape\n",
    "print X_test.shape\n",
    "print y_train[:3]\n",
    "print y_train.shape\n",
    "print y_valid.shape\n",
    "print y_test.shape\n",
    "\n",
    "print X_test_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_L2 = 0.0002\n",
    "batch_size = 128\n",
    "num_hidden_1 = 1024\n",
    "#num_hidden_2 = 300\n",
    "#num_hidden_3 = 50\n",
    "num_features = X_train.shape[1]\n",
    "num_labels = 12\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, num_features))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(X_valid)\n",
    "  tf_test_dataset = tf.constant(X_test)\n",
    "  tf_test_submit = tf.constant(X_test_submit)\n",
    "  \n",
    "  # Variables.\n",
    "  w = weight_variable(shape=[num_features, num_hidden_1])\n",
    "  b = bias_variable(shape=[num_hidden_1])\n",
    "\n",
    "  #w2 = weight_variable(shape=[num_hidden_1, num_hidden_2])\n",
    "  #b2 = bias_variable(shape=[num_hidden_2])\n",
    "\n",
    "  #w3 = weight_variable(shape=[num_hidden_2, num_hidden_3])\n",
    "  #b3 = bias_variable(shape=[num_hidden_3])\n",
    "\n",
    "  w4 = weight_variable(shape=[num_hidden_1, num_labels])\n",
    "  b4 = bias_variable(shape=[num_labels])\n",
    "  \n",
    "  # Training computation.\n",
    "  def model(data):\n",
    "    h = tf.nn.relu(tf.matmul(data, w) + b)\n",
    "    ##Dropout\n",
    "    keep_prob = tf.constant(1.)\n",
    "    #h2 = tf.tanh(tf.matmul(h, w2) + b2)\n",
    "    #h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "    #h3 = tf.tanh(tf.matmul(h2, w3) + b3)\n",
    "    #h3_drop = tf.tanh(tf.matmul(h2_drop, w3) + b3)\n",
    "    #h3_drop = tf.nn.dropout(h3_drop, keep_prob)\n",
    "    h4 = tf.matmul(h, w4) + b4\n",
    "    return h4\n",
    "  \n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # L2 regularization for the fully connected parameters.\n",
    "  #regularizers = tf.nn.l2_loss(w) + tf.nn.l2_loss(w4)\n",
    "  # Add the regularization term to the loss.\n",
    "  #loss += reg_L2 * 0.5 * regularizers\n",
    "  \n",
    "  # Optimizer.\n",
    "  ## with learning rate decay\n",
    "  ##global_step = tf.Variable(0, trainable=False) # count the number of steps taken.\n",
    "  ##learning_rate = tf.train.exponential_decay(1., global_step, 500, 0.6, staircase=False)\n",
    "  ##optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  optimizer = tf.train.AdagradOptimizer(.01).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, test, and test submission data.\n",
    "  def predict(data):\n",
    "    h = tf.nn.relu(tf.matmul(data, w) + b)\n",
    "    #h2 = tf.tanh(tf.matmul(h, w2) + b2)\n",
    "    #h3 = tf.tanh(tf.matmul(h2, w3) + b3)\n",
    "    h4 = tf.matmul(h, w4) + b4\n",
    "    return h4\n",
    "  train_prediction = tf.nn.softmax(predict(tf_train_dataset))\n",
    "  valid_prediction = tf.nn.softmax(predict(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(predict(tf_test_dataset))\n",
    "\n",
    "  submit_prediction = tf.nn.softmax(predict(tf_test_submit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "============\n",
      "Minibatch loss at step 0 : 3.26455\n",
      "Minibatch accuracy: 2.34%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Test accuracy: 58.78%\n",
      "====================\n",
      "Minibatch loss at step 300 : 1.16833\n",
      "Minibatch accuracy: 58.59%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Minibatch loss at step 600 : 1.36942\n",
      "Minibatch accuracy: 64.06%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Minibatch loss at step 900 : 1.13909\n",
      "Minibatch accuracy: 57.81%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Test accuracy: 58.78%\n",
      "====================\n",
      "Minibatch loss at step 1200 : 1.11844\n",
      "Minibatch accuracy: 61.72%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Minibatch loss at step 1500 : 1.03941\n",
      "Minibatch accuracy: 64.06%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-332-bc05c01609cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Initialized\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mstep_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Test accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mypred_submit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-332-bc05c01609cb>\u001b[0m in \u001b[0;36mstep_eval\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;31m#print global_step.eval(), learning_rate.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jjl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jjl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 404\u001b[0;31m                                target_list)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "    \n",
    "def step_eval():\n",
    "  for step in xrange(num_steps):\n",
    "    offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
    "    batch_data = X_train[offset:(offset + batch_size), :]\n",
    "    batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 300 == 0):\n",
    "      #print global_step.eval(), learning_rate.eval()\n",
    "      print \"Minibatch loss at step\", step, \":\", l\n",
    "      print \"Minibatch accuracy: %.2f%%\" % accuracy(predictions, batch_labels)\n",
    "      accuracy_valid = accuracy(valid_prediction.eval(), y_valid)\n",
    "      print \"Validation accuracy: %.2f%%\" % accuracy_valid\n",
    "      print \"-\" * 20\n",
    "      if accuracy_valid > 92.:\n",
    "        print \"Halted!\"\n",
    "        return\n",
    "    if (step % 1000 == 0):\n",
    "      print \"Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), y_test)\n",
    "      print \"=\" * 20\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print \"Initialized\\n\", \"=\"*12\n",
    "  step_eval()\n",
    "  print \"Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), y_test)\n",
    "  ypred_submit = submit_prediction.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00275282  0.00670136  0.00510201  0.00973255  0.02230456  0.01001685\n",
      "   0.01413022  0.57495332  0.00390214  0.00101802  0.30211538  0.04727076]\n",
      " [ 0.00274651  0.00668118  0.00512046  0.00975334  0.02227283  0.01004198\n",
      "   0.01409889  0.57516688  0.00390226  0.00101752  0.30192763  0.04727058]\n",
      " [ 0.00273304  0.00665983  0.00510894  0.00972562  0.02229475  0.01000752\n",
      "   0.01408009  0.57545155  0.00389516  0.00101317  0.30179265  0.04723767]\n",
      " [ 0.00274596  0.00669436  0.00510876  0.00974156  0.02229444  0.01002662\n",
      "   0.01412156  0.57517922  0.0039057   0.00101715  0.30187249  0.04729211]\n",
      " [ 0.00274236  0.00668534  0.00511654  0.00977065  0.0222552   0.01004988\n",
      "   0.01410146  0.57546836  0.00390035  0.00101695  0.30169925  0.0471937 ]]\n",
      "[[ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]]\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n"
     ]
    }
   ],
   "source": [
    "check = ypred_submit[2000:2004]\n",
    "print check\n",
    "print np.argsort(check)\n",
    "for i in xrange(len(check)):\n",
    "    print le.inverse_transform(np.argsort(check[i])[::-1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, var3, var15, imp_ent_var16_ult1, imp_op_var39_comer_ult1, imp_op_var39_comer_ult3, imp_op_var40_comer_ult1, imp_op_var40_comer_ult3, imp_op_var40_efect_ult1, imp_op_var40_efect_ult3, imp_op_var40_ult1, imp_op_var41_comer_ult1, imp_op_var41_comer_ult3, imp_op_var41_efect_ult1, imp_op_var41_efect_ult3, imp_op_var41_ult1, imp_op_var39_efect_ult1, imp_op_var39_efect_ult3, imp_op_var39_ult1, imp_sal_var16_ult1, ind_var1_0, ind_var1, ind_var2_0, ind_var2, ind_var5_0, ind_var5, ind_var6_0, ind_var6, ind_var8_0, ind_var8, ind_var12_0, ind_var12, ind_var13_0, ind_var13_corto_0, ind_var13_corto, ind_var13_largo_0, ind_var13_largo, ind_var13_medio_0, ind_var13_medio, ind_var13, ind_var14_0, ind_var14, ind_var17_0, ind_var17, ind_var18_0, ind_var18, ind_var19, ind_var20_0, ind_var20, ind_var24_0, ind_var24, ind_var25_cte, ind_var26_0, ind_var26_cte, ind_var26, ind_var25_0, ind_var25, ind_var27_0, ind_var28_0, ind_var28, ind_var27, ind_var29_0, ind_var29, ind_var30_0, ind_var30, ind_var31_0, ind_var31, ind_var32_cte, ind_var32_0, ind_var32, ind_var33_0, ind_var33, ind_var34_0, ind_var34, ind_var37_cte, ind_var37_0, ind_var37, ind_var39_0, ind_var40_0, ind_var40, ind_var41_0, ind_var41, ind_var39, ind_var44_0, ind_var44, ind_var46_0, ind_var46, num_var1_0, num_var1, num_var4, num_var5_0, num_var5, num_var6_0, num_var6, num_var8_0, num_var8, num_var12_0, num_var12, num_var13_0, num_var13_corto_0, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 371 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.saldo_var33 <0) & train.TARGET==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
