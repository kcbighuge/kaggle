{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Satisfaction\n",
    "https://www.kaggle.com/c/santander-customer-satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Exploratory analysis\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                   0                        0   \n",
       "1   3     2     34                   0                        0   \n",
       "2   4     2     23                   0                        0   \n",
       "3   8     2     37                   0                      195   \n",
       "4  10     2     39                   0                        0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                      195                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
       "0                        0                        0   ...     \n",
       "1                        0                        0   ...     \n",
       "2                        0                        0   ...     \n",
       "3                        0                        0   ...     \n",
       "4                        0                        0   ...     \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                        0                        0                       0   \n",
       "1                        0                        0                       0   \n",
       "2                        0                        0                       0   \n",
       "3                        0                        0                       0   \n",
       "4                        0                        0                       0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                       0                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                       0                       0   39205.170000       0  \n",
       "1                       0                       0   49278.030000       0  \n",
       "2                       0                       0   67333.770000       0  \n",
       "3                       0                       0   64007.970000       0  \n",
       "4                       0                       0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75813</th>\n",
       "      <td>151831</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40243.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75814</th>\n",
       "      <td>151832</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146961.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75815</th>\n",
       "      <td>151833</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167299.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75816</th>\n",
       "      <td>151834</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75817</th>\n",
       "      <td>151837</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "75813  151831     2     23                   0                        0   \n",
       "75814  151832     2     26                   0                        0   \n",
       "75815  151833     2     24                   0                        0   \n",
       "75816  151834     2     40                   0                        0   \n",
       "75817  151837     2     23                   0                        0   \n",
       "\n",
       "       imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       imp_op_var40_comer_ult3  imp_op_var40_efect_ult1  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       imp_op_var40_efect_ult3      ...        saldo_medio_var29_ult3  \\\n",
       "75813                        0      ...                             0   \n",
       "75814                        0      ...                             0   \n",
       "75815                        0      ...                             0   \n",
       "75816                        0      ...                             0   \n",
       "75817                        0      ...                             0   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "75813                       0                       0   \n",
       "75814                       0                       0   \n",
       "75815                       0                       0   \n",
       "75816                       0                       0   \n",
       "75817                       0                       0   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "75813                        0                        0   \n",
       "75814                        0                        0   \n",
       "75815                        0                        0   \n",
       "75816                        0                        0   \n",
       "75817                        0                        0   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  \n",
       "75813                       0                       0   40243.200000  \n",
       "75814                       0                       0  146961.300000  \n",
       "75815                       0                       0  167299.770000  \n",
       "75816                       0                       0  117310.979016  \n",
       "75817                       0                       0  117310.979016  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>117235.809430</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>182664.598503</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5163.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67870.612500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106409.160000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118756.252500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>22034738.760000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3      ...       \\\n",
       "count             76020.000000             76020.000000      ...        \n",
       "mean                  0.412946                 0.567352      ...        \n",
       "std                  30.604864                36.513513      ...        \n",
       "min                   0.000000                 0.000000      ...        \n",
       "25%                   0.000000                 0.000000      ...        \n",
       "50%                   0.000000                 0.000000      ...        \n",
       "75%                   0.000000                 0.000000      ...        \n",
       "max                6600.000000              6600.000000      ...        \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3            var38  \\\n",
       "count            76020.000000            76020.000000     76020.000000   \n",
       "mean                76.026165               56.614351    117235.809430   \n",
       "std               4040.337842             2852.579397    182664.598503   \n",
       "min                  0.000000                0.000000      5163.750000   \n",
       "25%                  0.000000                0.000000     67870.612500   \n",
       "50%                  0.000000                0.000000    106409.160000   \n",
       "75%                  0.000000                0.000000    118756.252500   \n",
       "max             681462.900000           397884.300000  22034738.760000   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'seaborn-darkgrid', u'seaborn-notebook', u'classic', u'seaborn-ticks', u'grayscale', u'bmh', u'seaborn-talk', u'dark_background', u'ggplot', u'fivethirtyeight', u'seaborn-colorblind', u'seaborn-deep', u'seaborn-whitegrid', u'seaborn-bright', u'seaborn-poster', u'seaborn-muted', u'seaborn-paper', u'seaborn-white', u'seaborn-pastel', u'seaborn-dark', u'seaborn-dark-palette']\n"
     ]
    }
   ],
   "source": [
    "print plt.style.available\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3008"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['TARGET']==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use for spltting up combined train+test data, recording predictions\n",
    "labels = train['TARGET'].values\n",
    "df_train = train.drop(['TARGET'], axis=1)\n",
    "df_test = test.copy()\n",
    "id_test = test['ID']\n",
    "piv_train = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var3                             0\n",
       "var15                            0\n",
       "imp_ent_var16_ult1               0\n",
       "imp_op_var39_comer_ult1          0\n",
       "imp_op_var39_comer_ult3          0\n",
       "imp_op_var40_comer_ult1          0\n",
       "imp_op_var40_comer_ult3          0\n",
       "imp_op_var40_efect_ult1          0\n",
       "imp_op_var40_efect_ult3          0\n",
       "imp_op_var40_ult1                0\n",
       "imp_op_var41_comer_ult1          0\n",
       "imp_op_var41_comer_ult3          0\n",
       "imp_op_var41_efect_ult1          0\n",
       "imp_op_var41_efect_ult3          0\n",
       "imp_op_var41_ult1                0\n",
       "imp_op_var39_efect_ult1          0\n",
       "imp_op_var39_efect_ult3          0\n",
       "imp_op_var39_ult1                0\n",
       "imp_sal_var16_ult1               0\n",
       "ind_var1_0                       0\n",
       "ind_var1                         0\n",
       "ind_var2_0                       0\n",
       "ind_var2                         0\n",
       "ind_var5_0                       0\n",
       "ind_var5                         0\n",
       "ind_var6_0                       0\n",
       "ind_var6                         0\n",
       "ind_var8_0                       0\n",
       "ind_var8                         0\n",
       "ind_var12_0                      0\n",
       "                                ..\n",
       "saldo_medio_var12_ult3           0\n",
       "saldo_medio_var13_corto_hace2    0\n",
       "saldo_medio_var13_corto_hace3    0\n",
       "saldo_medio_var13_corto_ult1     0\n",
       "saldo_medio_var13_corto_ult3     0\n",
       "saldo_medio_var13_largo_hace2    0\n",
       "saldo_medio_var13_largo_hace3    0\n",
       "saldo_medio_var13_largo_ult1     0\n",
       "saldo_medio_var13_largo_ult3     0\n",
       "saldo_medio_var13_medio_hace2    0\n",
       "saldo_medio_var13_medio_hace3    0\n",
       "saldo_medio_var13_medio_ult1     0\n",
       "saldo_medio_var13_medio_ult3     0\n",
       "saldo_medio_var17_hace2          0\n",
       "saldo_medio_var17_hace3          0\n",
       "saldo_medio_var17_ult1           0\n",
       "saldo_medio_var17_ult3           0\n",
       "saldo_medio_var29_hace2          0\n",
       "saldo_medio_var29_hace3          0\n",
       "saldo_medio_var29_ult1           0\n",
       "saldo_medio_var29_ult3           0\n",
       "saldo_medio_var33_hace2          0\n",
       "saldo_medio_var33_hace3          0\n",
       "saldo_medio_var33_ult1           0\n",
       "saldo_medio_var33_ult3           0\n",
       "saldo_medio_var44_hace2          0\n",
       "saldo_medio_var44_hace3          0\n",
       "saldo_medio_var44_ult1           0\n",
       "saldo_medio_var44_ult3           0\n",
       "var38                            0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a DataFrame with train+test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "# Removing id\n",
    "# we can also remove id later\n",
    "df_all = df_all.drop(['ID'], axis=1)\n",
    "(df_all.isnull().sum() / df_all.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filling nan\n",
    "df_all = df_all.fillna(-1)\n",
    "df_all_copy = df_all.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Look at important features found here:  \n",
    "https://www.kaggle.com/cast42/santander-customer-satisfaction/xgboost-with-early-stopping/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add sum of zeros per row as new feature\n",
    "df_all['n0'] = (df_all ==0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var38</th>\n",
       "      <th>var15</th>\n",
       "      <th>n0</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>saldo_var30</th>\n",
       "      <th>saldo_medio_var5_hace3</th>\n",
       "      <th>num_var45_hace3</th>\n",
       "      <th>saldo_medio_var5_hace2</th>\n",
       "      <th>num_var22_ult3</th>\n",
       "      <th>num_var45_ult3</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_var42</th>\n",
       "      <th>saldo_var5</th>\n",
       "      <th>num_meses_var39_vig_ult3</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39205.170000</td>\n",
       "      <td>23</td>\n",
       "      <td>355</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49278.030000</td>\n",
       "      <td>34</td>\n",
       "      <td>329</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>88.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67333.770000</td>\n",
       "      <td>23</td>\n",
       "      <td>340</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64007.970000</td>\n",
       "      <td>37</td>\n",
       "      <td>309</td>\n",
       "      <td>138.84</td>\n",
       "      <td>70.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>186.09</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>91.56</td>\n",
       "      <td>70.62</td>\n",
       "      <td>70.62</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117310.979016</td>\n",
       "      <td>39</td>\n",
       "      <td>319</td>\n",
       "      <td>13501.47</td>\n",
       "      <td>135003.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>40501.08</td>\n",
       "      <td>135003.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           var38  var15   n0  saldo_medio_var5_ult3  saldo_var30  \\\n",
       "0   39205.170000     23  355                   0.00         0.00   \n",
       "1   49278.030000     34  329                   0.00       300.00   \n",
       "2   67333.770000     23  340                   2.07         3.00   \n",
       "3   64007.970000     37  309                 138.84        70.62   \n",
       "4  117310.979016     39  319               13501.47    135003.00   \n",
       "\n",
       "   saldo_medio_var5_hace3  num_var45_hace3  saldo_medio_var5_hace2  \\\n",
       "0                    0.00                0                    0.00   \n",
       "1                   88.89                0                    0.00   \n",
       "2                    0.18                0                    3.00   \n",
       "3                    0.00                3                  186.09   \n",
       "4                    0.30                0                    3.00   \n",
       "\n",
       "   num_var22_ult3  num_var45_ult3  saldo_medio_var5_ult1  saldo_var42  \\\n",
       "0               0               0                   0.00         0.00   \n",
       "1               0               0                   0.00         0.00   \n",
       "2               0               0                   3.00         3.00   \n",
       "3               3              48                  91.56        70.62   \n",
       "4               9               0               40501.08    135003.00   \n",
       "\n",
       "   saldo_var5  num_meses_var39_vig_ult3  imp_op_var41_comer_ult3  \n",
       "0        0.00                         2                        0  \n",
       "1        0.00                         2                        0  \n",
       "2        3.00                         1                        0  \n",
       "3       70.62                         1                      195  \n",
       "4        0.00                         2                        0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at top features\n",
    "top_features = ['var38', 'var15', 'n0', 'saldo_medio_var5_ult3', 'saldo_var30', 'saldo_medio_var5_hace3', \n",
    "                'num_var45_hace3', 'saldo_medio_var5_hace2', 'num_var22_ult3', 'num_var45_ult3',\n",
    "                'saldo_medio_var5_ult1', 'saldo_var42', 'saldo_var5', 'num_meses_var39_vig_ult3',\n",
    "                'imp_op_var41_comer_ult3']\n",
    "\n",
    "df_all[top_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### var38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAECCAYAAAAy++cMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11afbd350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at most important feature\n",
    "plt.hist(np.log(df_all['var38']), bins=50)\n",
    "plt.gcf().set_size_inches(9,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "2. Feature engineering\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAECCAYAAADgq+1UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c8b0210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at distribution of number of zeros per row\n",
    "plt.hist(df_all['n0'], bins=100)\n",
    "plt.gcf().set_size_inches(9,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: PCA reduced sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: keep user id separate\n",
    "pivot_ids = pivot_uu['user_id']\n",
    "pivot_uu = pivot_uu.drop('user_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994647860711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  4.55784016e-01,   1.76720370e-01,   1.34333992e-01,\n",
       "         1.04366961e-01,   4.46364281e-02,   2.29000872e-02,\n",
       "         9.85413653e-03,   8.33610964e-03,   7.09086715e-03,\n",
       "         4.94513283e-03,   3.90182942e-03,   3.07658093e-03,\n",
       "         2.37547336e-03,   1.89985253e-03,   1.64290753e-03,\n",
       "         1.59587043e-03,   1.49620374e-03,   1.31682851e-03,\n",
       "         1.11501027e-03,   1.08507240e-03,   9.01577834e-04,\n",
       "         8.74137626e-04,   7.94024601e-04,   7.27729297e-04,\n",
       "         6.59200877e-04,   5.53850220e-04,   4.53780643e-04,\n",
       "         4.39955814e-04,   4.01040885e-04,   3.68832672e-04])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30, copy=True, whiten=False)\n",
    "\n",
    "# fit the data\n",
    "pca.fit(pivot_uu)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print sum(pca.explained_variance_ratio_)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135478, 30)\n"
     ]
    }
   ],
   "source": [
    "events_pca = pca.transform(pivot_uu)\n",
    "print events_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.552858</td>\n",
       "      <td>4.563340</td>\n",
       "      <td>-4.783074</td>\n",
       "      <td>1.423241</td>\n",
       "      <td>-0.482374</td>\n",
       "      <td>1.426581</td>\n",
       "      <td>-0.305765</td>\n",
       "      <td>-0.370464</td>\n",
       "      <td>-0.232111</td>\n",
       "      <td>-1.206425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314600</td>\n",
       "      <td>-0.434894</td>\n",
       "      <td>2.617254</td>\n",
       "      <td>1.029291</td>\n",
       "      <td>-0.037263</td>\n",
       "      <td>0.281922</td>\n",
       "      <td>0.084339</td>\n",
       "      <td>-0.141330</td>\n",
       "      <td>0.170418</td>\n",
       "      <td>00023iyk9l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.696191</td>\n",
       "      <td>3.084447</td>\n",
       "      <td>-4.693928</td>\n",
       "      <td>5.745356</td>\n",
       "      <td>-0.465075</td>\n",
       "      <td>1.943602</td>\n",
       "      <td>-1.864972</td>\n",
       "      <td>3.124069</td>\n",
       "      <td>0.138877</td>\n",
       "      <td>3.662305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043853</td>\n",
       "      <td>-0.266465</td>\n",
       "      <td>-0.461326</td>\n",
       "      <td>-0.394993</td>\n",
       "      <td>0.171884</td>\n",
       "      <td>0.112885</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.093282</td>\n",
       "      <td>-0.176547</td>\n",
       "      <td>0010k6l0om</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.387948</td>\n",
       "      <td>29.140816</td>\n",
       "      <td>24.023564</td>\n",
       "      <td>-17.856232</td>\n",
       "      <td>-16.147731</td>\n",
       "      <td>-0.258195</td>\n",
       "      <td>0.627195</td>\n",
       "      <td>-3.518666</td>\n",
       "      <td>1.841621</td>\n",
       "      <td>-0.190239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196947</td>\n",
       "      <td>-0.286164</td>\n",
       "      <td>-0.169058</td>\n",
       "      <td>0.079312</td>\n",
       "      <td>-0.416128</td>\n",
       "      <td>-0.007227</td>\n",
       "      <td>-0.167309</td>\n",
       "      <td>0.093205</td>\n",
       "      <td>-0.071878</td>\n",
       "      <td>001wyh0pz8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.891381</td>\n",
       "      <td>0.613752</td>\n",
       "      <td>-4.639629</td>\n",
       "      <td>-5.676685</td>\n",
       "      <td>-3.519701</td>\n",
       "      <td>1.321304</td>\n",
       "      <td>-0.287688</td>\n",
       "      <td>0.325089</td>\n",
       "      <td>-3.123836</td>\n",
       "      <td>-0.356795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.257453</td>\n",
       "      <td>0.636374</td>\n",
       "      <td>-0.187680</td>\n",
       "      <td>0.239828</td>\n",
       "      <td>-0.803435</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>-0.499276</td>\n",
       "      <td>-0.008971</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0028jgx1x1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.617184</td>\n",
       "      <td>-120.531591</td>\n",
       "      <td>143.144478</td>\n",
       "      <td>-40.109561</td>\n",
       "      <td>4.322015</td>\n",
       "      <td>13.913673</td>\n",
       "      <td>0.520738</td>\n",
       "      <td>-4.011590</td>\n",
       "      <td>6.561841</td>\n",
       "      <td>3.298432</td>\n",
       "      <td>...</td>\n",
       "      <td>6.185851</td>\n",
       "      <td>24.327351</td>\n",
       "      <td>-6.071458</td>\n",
       "      <td>14.120418</td>\n",
       "      <td>-9.333167</td>\n",
       "      <td>0.802146</td>\n",
       "      <td>-1.583475</td>\n",
       "      <td>-1.613278</td>\n",
       "      <td>4.330721</td>\n",
       "      <td>002qnbzfs5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2          3          4          5  \\\n",
       "0  -11.552858    4.563340   -4.783074   1.423241  -0.482374   1.426581   \n",
       "1   -1.696191    3.084447   -4.693928   5.745356  -0.465075   1.943602   \n",
       "2   30.387948   29.140816   24.023564 -17.856232 -16.147731  -0.258195   \n",
       "3   -6.891381    0.613752   -4.639629  -5.676685  -3.519701   1.321304   \n",
       "4  151.617184 -120.531591  143.144478 -40.109561   4.322015  13.913673   \n",
       "\n",
       "          6         7         8         9     ...            21         22  \\\n",
       "0 -0.305765 -0.370464 -0.232111 -1.206425     ...      0.314600  -0.434894   \n",
       "1 -1.864972  3.124069  0.138877  3.662305     ...      0.043853  -0.266465   \n",
       "2  0.627195 -3.518666  1.841621 -0.190239     ...     -0.196947  -0.286164   \n",
       "3 -0.287688  0.325089 -3.123836 -0.356795     ...     -0.257453   0.636374   \n",
       "4  0.520738 -4.011590  6.561841  3.298432     ...      6.185851  24.327351   \n",
       "\n",
       "         23         24        25        26        27        28        29  \\\n",
       "0  2.617254   1.029291 -0.037263  0.281922  0.084339 -0.141330  0.170418   \n",
       "1 -0.461326  -0.394993  0.171884  0.112885  0.015717  0.093282 -0.176547   \n",
       "2 -0.169058   0.079312 -0.416128 -0.007227 -0.167309  0.093205 -0.071878   \n",
       "3 -0.187680   0.239828 -0.803435  0.009918 -0.499276 -0.008971  0.014002   \n",
       "4 -6.071458  14.120418 -9.333167  0.802146 -1.583475 -1.613278  4.330721   \n",
       "\n",
       "      user_id  \n",
       "0  00023iyk9l  \n",
       "1  0010k6l0om  \n",
       "2  001wyh0pz8  \n",
       "3  0028jgx1x1  \n",
       "4  002qnbzfs5  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_merge = pd.concat((pd.DataFrame(events_pca), pivot_ids), axis=1)\n",
    "sessions_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting train and test\n",
    "vals = df_all.values\n",
    "X = vals[:piv_train]\n",
    "X_test_submit = vals[piv_train:]\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PCA-reduced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting train and test with PCA-reduced data\n",
    "vals = pd.DataFrame(pca.transform(df_all)).values\n",
    "X = vals[:piv_train]\n",
    "X_test_submit = vals[piv_train:]\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    normalized_features = (feature_matrix - norms/2) / norms\n",
    "        \n",
    "    return(normalized_features, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Splitting train and test and normalizing\n",
    "vals_norm,_ = normalize_features(vals)\n",
    "X_norm = vals_norm[:piv_train]\n",
    "X_test_norm = vals_norm[piv_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213451, 316)\n",
      "(62096, 316)\n"
     ]
    }
   ],
   "source": [
    "print X_norm.shape\n",
    "print X_test_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Split train data further into train/validation/test sets\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** convert labels to vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020,)\n"
     ]
    }
   ],
   "source": [
    "y_copy = y.copy()\n",
    "print y_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reformat labels as vector\n",
    "def reformat(labels, num_labels=12):\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)  # convert label to vector\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213451, 12)\n"
     ]
    }
   ],
   "source": [
    "## variable for new label vectors\n",
    "y_vec = reformat(y_copy)\n",
    "print y_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## keep copy of X_test_submit\n",
    "X_test_copy = X_test_submit.copy()\n",
    "#X_test_submit = X_test_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert test submission dtype\n",
    "X_test_submit = X_test_norm.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## split normalized data into train and test\n",
    "X_tv, X_test, y_tv, y_test = cross_validation.train_test_split(X_norm.astype('float32'), \\\n",
    "                                                               y_vec.astype('float32'), test_size=.05, random_state=205)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = cross_validation.train_test_split(X_tv, y_tv, \\\n",
    "                                                                       test_size=.05, random_state=71511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## split into train and validation\n",
    "## use X,y for full training data\n",
    "X_train, X_valid, y_train, y_valid = cross_validation.train_test_split(X, y, \\\n",
    "                                                                       test_size=.2, random_state=415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "\n",
    "## Make scorer\n",
    "auc_scorer = metrics.make_scorer(metrics.roc_auc_score, greater_is_better=True)\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, greater_is_better=True, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Random forest\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create cv search objec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "'''\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \\\n",
    "                            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \\\n",
    "                            max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, \\\n",
    "                            n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "'''\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "est = RandomForestClassifier(n_estimators=100, max_depth=None, class_weight='balanced', random_state=415)\n",
    "parameters = {'min_samples_split': [2, 32]\n",
    "             }\n",
    "reg = grid_search.GridSearchCV(est, parameters, scoring=auc_scorer, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. SVM\n",
    "http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# Setup a Classifier\n",
    "clf = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, \\\n",
    "                  shrinking=True, probability=False, tol=0.001, cache_size=200, \\\n",
    "                  class_weight='balanced', verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)\n",
    "# tune parameter with at least 3 settings\n",
    "parameters = {'C': (1.0, 0.2),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PCA reduced data\n",
    "X_reduced = pca.transform(X)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. XGBoost\n",
    "https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Classifier\n",
    "# try using... objective: multi:softprob, rank:pairwise\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "ratio = float(np.sum(y == 1)) / np.sum(y==0)\n",
    "est = XGBClassifier(max_depth=7, learning_rate=0.1, n_estimators=256,\n",
    "                    objective='binary:logistic', subsample=1.0, colsample_bytree=.5, \n",
    "                    min_child_weight = 3, scale_pos_weight = ratio, seed=123)                  \n",
    "\n",
    "param = {\n",
    "    'objective':'multi:softprob',                    \n",
    "    'max_depth':6, \n",
    "    'learning_rate':0.25, \n",
    "    'n_estimators':43,                 \n",
    "    'subsample':0.6, \n",
    "    'colsample_bytree':0.6,\n",
    "    'num_class' :12\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_set = [(X_train,y_train), (X_valid,y_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until validation_1 error hasn't decreased in 50 rounds.\n",
      "[0]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[1]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[2]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[3]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[4]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[5]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[6]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[7]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[8]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[9]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[10]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[11]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[12]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[13]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[14]\tvalidation_0-auc:0.500000\tvalidation_1-auc:0.500000\n",
      "[15]\tvalidation_0-auc:0.722498\tvalidation_1-auc:0.685326\n",
      "[16]\tvalidation_0-auc:0.722392\tvalidation_1-auc:0.685144\n",
      "[17]\tvalidation_0-auc:0.722392\tvalidation_1-auc:0.685144\n",
      "[18]\tvalidation_0-auc:0.718160\tvalidation_1-auc:0.680099\n",
      "[19]\tvalidation_0-auc:0.718160\tvalidation_1-auc:0.680099\n",
      "[20]\tvalidation_0-auc:0.719666\tvalidation_1-auc:0.681423\n",
      "[21]\tvalidation_0-auc:0.719666\tvalidation_1-auc:0.681423\n",
      "[22]\tvalidation_0-auc:0.719666\tvalidation_1-auc:0.681423\n",
      "[23]\tvalidation_0-auc:0.719666\tvalidation_1-auc:0.681423\n",
      "[24]\tvalidation_0-auc:0.719666\tvalidation_1-auc:0.681423\n",
      "[25]\tvalidation_0-auc:0.724806\tvalidation_1-auc:0.686439\n",
      "[26]\tvalidation_0-auc:0.724806\tvalidation_1-auc:0.686439\n",
      "[27]\tvalidation_0-auc:0.720993\tvalidation_1-auc:0.683181\n",
      "[28]\tvalidation_0-auc:0.722167\tvalidation_1-auc:0.684136\n",
      "[29]\tvalidation_0-auc:0.725275\tvalidation_1-auc:0.686700\n",
      "[30]\tvalidation_0-auc:0.725503\tvalidation_1-auc:0.687004\n",
      "[31]\tvalidation_0-auc:0.725362\tvalidation_1-auc:0.686782\n",
      "[32]\tvalidation_0-auc:0.723854\tvalidation_1-auc:0.685273\n",
      "[33]\tvalidation_0-auc:0.731592\tvalidation_1-auc:0.696681\n",
      "[34]\tvalidation_0-auc:0.734317\tvalidation_1-auc:0.698794\n",
      "[35]\tvalidation_0-auc:0.735253\tvalidation_1-auc:0.700344\n",
      "[36]\tvalidation_0-auc:0.738660\tvalidation_1-auc:0.705246\n",
      "[37]\tvalidation_0-auc:0.779413\tvalidation_1-auc:0.752202\n",
      "[38]\tvalidation_0-auc:0.795764\tvalidation_1-auc:0.775025\n",
      "[39]\tvalidation_0-auc:0.798790\tvalidation_1-auc:0.777794\n",
      "[40]\tvalidation_0-auc:0.801900\tvalidation_1-auc:0.778532\n",
      "[41]\tvalidation_0-auc:0.804948\tvalidation_1-auc:0.781863\n",
      "[42]\tvalidation_0-auc:0.804454\tvalidation_1-auc:0.780703\n",
      "[43]\tvalidation_0-auc:0.804193\tvalidation_1-auc:0.779790\n",
      "[44]\tvalidation_0-auc:0.804073\tvalidation_1-auc:0.779062\n",
      "[45]\tvalidation_0-auc:0.804787\tvalidation_1-auc:0.779785\n",
      "[46]\tvalidation_0-auc:0.809681\tvalidation_1-auc:0.785751\n",
      "[47]\tvalidation_0-auc:0.814329\tvalidation_1-auc:0.793171\n",
      "[48]\tvalidation_0-auc:0.817416\tvalidation_1-auc:0.798363\n",
      "[49]\tvalidation_0-auc:0.819353\tvalidation_1-auc:0.801184\n",
      "[50]\tvalidation_0-auc:0.818154\tvalidation_1-auc:0.798512\n",
      "[51]\tvalidation_0-auc:0.816567\tvalidation_1-auc:0.796146\n",
      "[52]\tvalidation_0-auc:0.820041\tvalidation_1-auc:0.800486\n",
      "[53]\tvalidation_0-auc:0.819256\tvalidation_1-auc:0.798593\n",
      "[54]\tvalidation_0-auc:0.822184\tvalidation_1-auc:0.802846\n",
      "[55]\tvalidation_0-auc:0.822673\tvalidation_1-auc:0.801488\n",
      "[56]\tvalidation_0-auc:0.826059\tvalidation_1-auc:0.806630\n",
      "[57]\tvalidation_0-auc:0.826832\tvalidation_1-auc:0.806771\n",
      "[58]\tvalidation_0-auc:0.830447\tvalidation_1-auc:0.812669\n",
      "[59]\tvalidation_0-auc:0.832214\tvalidation_1-auc:0.814484\n",
      "[60]\tvalidation_0-auc:0.834705\tvalidation_1-auc:0.818342\n",
      "[61]\tvalidation_0-auc:0.836158\tvalidation_1-auc:0.820731\n",
      "[62]\tvalidation_0-auc:0.835783\tvalidation_1-auc:0.818887\n",
      "[63]\tvalidation_0-auc:0.835689\tvalidation_1-auc:0.818400\n",
      "[64]\tvalidation_0-auc:0.837316\tvalidation_1-auc:0.821355\n",
      "[65]\tvalidation_0-auc:0.838907\tvalidation_1-auc:0.824055\n",
      "[66]\tvalidation_0-auc:0.838989\tvalidation_1-auc:0.823630\n",
      "[67]\tvalidation_0-auc:0.839321\tvalidation_1-auc:0.823313\n",
      "[68]\tvalidation_0-auc:0.840687\tvalidation_1-auc:0.826111\n",
      "[69]\tvalidation_0-auc:0.840412\tvalidation_1-auc:0.825080\n",
      "[70]\tvalidation_0-auc:0.840358\tvalidation_1-auc:0.824626\n",
      "[71]\tvalidation_0-auc:0.841736\tvalidation_1-auc:0.826505\n",
      "[72]\tvalidation_0-auc:0.843029\tvalidation_1-auc:0.828529\n",
      "[73]\tvalidation_0-auc:0.843607\tvalidation_1-auc:0.829355\n",
      "[74]\tvalidation_0-auc:0.844445\tvalidation_1-auc:0.830616\n",
      "[75]\tvalidation_0-auc:0.844332\tvalidation_1-auc:0.829753\n",
      "[76]\tvalidation_0-auc:0.845119\tvalidation_1-auc:0.830909\n",
      "[77]\tvalidation_0-auc:0.845467\tvalidation_1-auc:0.831279\n",
      "[78]\tvalidation_0-auc:0.845412\tvalidation_1-auc:0.830588\n",
      "[79]\tvalidation_0-auc:0.845967\tvalidation_1-auc:0.831860\n",
      "[80]\tvalidation_0-auc:0.846462\tvalidation_1-auc:0.832560\n",
      "[81]\tvalidation_0-auc:0.846745\tvalidation_1-auc:0.833021\n",
      "[82]\tvalidation_0-auc:0.847114\tvalidation_1-auc:0.833612\n",
      "[83]\tvalidation_0-auc:0.847484\tvalidation_1-auc:0.834293\n",
      "[84]\tvalidation_0-auc:0.847856\tvalidation_1-auc:0.834339\n",
      "[85]\tvalidation_0-auc:0.848161\tvalidation_1-auc:0.834377\n",
      "[86]\tvalidation_0-auc:0.848552\tvalidation_1-auc:0.834864\n",
      "[87]\tvalidation_0-auc:0.848669\tvalidation_1-auc:0.835051\n",
      "[88]\tvalidation_0-auc:0.848942\tvalidation_1-auc:0.834814\n",
      "[89]\tvalidation_0-auc:0.849212\tvalidation_1-auc:0.834832\n",
      "[90]\tvalidation_0-auc:0.849465\tvalidation_1-auc:0.835289\n",
      "[91]\tvalidation_0-auc:0.849648\tvalidation_1-auc:0.835542\n",
      "[92]\tvalidation_0-auc:0.849832\tvalidation_1-auc:0.835694\n",
      "[93]\tvalidation_0-auc:0.849931\tvalidation_1-auc:0.835914\n",
      "[94]\tvalidation_0-auc:0.850028\tvalidation_1-auc:0.836150\n",
      "[95]\tvalidation_0-auc:0.850260\tvalidation_1-auc:0.836121\n",
      "[96]\tvalidation_0-auc:0.850440\tvalidation_1-auc:0.836238\n",
      "[97]\tvalidation_0-auc:0.850561\tvalidation_1-auc:0.836411\n",
      "[98]\tvalidation_0-auc:0.850708\tvalidation_1-auc:0.836367\n",
      "[99]\tvalidation_0-auc:0.850958\tvalidation_1-auc:0.836455\n",
      "[100]\tvalidation_0-auc:0.851071\tvalidation_1-auc:0.836648\n",
      "[101]\tvalidation_0-auc:0.851207\tvalidation_1-auc:0.836789\n",
      "[102]\tvalidation_0-auc:0.851391\tvalidation_1-auc:0.836852\n",
      "[103]\tvalidation_0-auc:0.851543\tvalidation_1-auc:0.836769\n",
      "[104]\tvalidation_0-auc:0.851794\tvalidation_1-auc:0.836847\n",
      "[105]\tvalidation_0-auc:0.851928\tvalidation_1-auc:0.837018\n",
      "[106]\tvalidation_0-auc:0.852072\tvalidation_1-auc:0.837371\n",
      "[107]\tvalidation_0-auc:0.852230\tvalidation_1-auc:0.837385\n",
      "[108]\tvalidation_0-auc:0.852612\tvalidation_1-auc:0.837607\n",
      "[109]\tvalidation_0-auc:0.852776\tvalidation_1-auc:0.837612\n",
      "[110]\tvalidation_0-auc:0.852831\tvalidation_1-auc:0.837756\n",
      "[111]\tvalidation_0-auc:0.852936\tvalidation_1-auc:0.837734\n",
      "[112]\tvalidation_0-auc:0.853051\tvalidation_1-auc:0.837610\n",
      "[113]\tvalidation_0-auc:0.853234\tvalidation_1-auc:0.837954\n",
      "[114]\tvalidation_0-auc:0.853374\tvalidation_1-auc:0.838059\n",
      "[115]\tvalidation_0-auc:0.853527\tvalidation_1-auc:0.838077\n",
      "[116]\tvalidation_0-auc:0.853691\tvalidation_1-auc:0.838263\n",
      "[117]\tvalidation_0-auc:0.853853\tvalidation_1-auc:0.838416\n",
      "[118]\tvalidation_0-auc:0.854020\tvalidation_1-auc:0.838424\n",
      "[119]\tvalidation_0-auc:0.854187\tvalidation_1-auc:0.838530\n",
      "[120]\tvalidation_0-auc:0.854328\tvalidation_1-auc:0.838499\n",
      "[121]\tvalidation_0-auc:0.854473\tvalidation_1-auc:0.838446\n",
      "[122]\tvalidation_0-auc:0.854612\tvalidation_1-auc:0.838442\n",
      "[123]\tvalidation_0-auc:0.854694\tvalidation_1-auc:0.838523\n",
      "[124]\tvalidation_0-auc:0.854775\tvalidation_1-auc:0.838724\n",
      "[125]\tvalidation_0-auc:0.854862\tvalidation_1-auc:0.838799\n",
      "[126]\tvalidation_0-auc:0.855039\tvalidation_1-auc:0.838843\n",
      "[127]\tvalidation_0-auc:0.855115\tvalidation_1-auc:0.838948\n",
      "[128]\tvalidation_0-auc:0.855349\tvalidation_1-auc:0.838971\n",
      "[129]\tvalidation_0-auc:0.855457\tvalidation_1-auc:0.838911\n",
      "[130]\tvalidation_0-auc:0.855553\tvalidation_1-auc:0.838820\n",
      "[131]\tvalidation_0-auc:0.855671\tvalidation_1-auc:0.838853\n",
      "[132]\tvalidation_0-auc:0.855776\tvalidation_1-auc:0.838953\n",
      "[133]\tvalidation_0-auc:0.855951\tvalidation_1-auc:0.838941\n",
      "[134]\tvalidation_0-auc:0.856040\tvalidation_1-auc:0.839020\n",
      "[135]\tvalidation_0-auc:0.856199\tvalidation_1-auc:0.839076\n",
      "[136]\tvalidation_0-auc:0.856309\tvalidation_1-auc:0.839038\n",
      "[137]\tvalidation_0-auc:0.856385\tvalidation_1-auc:0.839069\n",
      "[138]\tvalidation_0-auc:0.856494\tvalidation_1-auc:0.838944\n",
      "[139]\tvalidation_0-auc:0.856654\tvalidation_1-auc:0.838941\n",
      "[140]\tvalidation_0-auc:0.856769\tvalidation_1-auc:0.839028\n",
      "[141]\tvalidation_0-auc:0.856886\tvalidation_1-auc:0.838908\n",
      "[142]\tvalidation_0-auc:0.856966\tvalidation_1-auc:0.838937\n",
      "[143]\tvalidation_0-auc:0.857027\tvalidation_1-auc:0.838890\n",
      "[144]\tvalidation_0-auc:0.857110\tvalidation_1-auc:0.838806\n",
      "[145]\tvalidation_0-auc:0.857251\tvalidation_1-auc:0.838836\n",
      "[146]\tvalidation_0-auc:0.857383\tvalidation_1-auc:0.838795\n",
      "[147]\tvalidation_0-auc:0.857507\tvalidation_1-auc:0.838790\n",
      "[148]\tvalidation_0-auc:0.857562\tvalidation_1-auc:0.838713\n",
      "[149]\tvalidation_0-auc:0.857695\tvalidation_1-auc:0.838768\n",
      "[150]\tvalidation_0-auc:0.857846\tvalidation_1-auc:0.838741\n",
      "[151]\tvalidation_0-auc:0.857974\tvalidation_1-auc:0.838727\n",
      "[152]\tvalidation_0-auc:0.858064\tvalidation_1-auc:0.838713\n",
      "[153]\tvalidation_0-auc:0.858239\tvalidation_1-auc:0.838791\n",
      "[154]\tvalidation_0-auc:0.858387\tvalidation_1-auc:0.838821\n",
      "[155]\tvalidation_0-auc:0.858483\tvalidation_1-auc:0.838775\n",
      "[156]\tvalidation_0-auc:0.858568\tvalidation_1-auc:0.838845\n",
      "[157]\tvalidation_0-auc:0.858717\tvalidation_1-auc:0.838927\n",
      "[158]\tvalidation_0-auc:0.858829\tvalidation_1-auc:0.838884\n",
      "[159]\tvalidation_0-auc:0.858955\tvalidation_1-auc:0.838978\n",
      "[160]\tvalidation_0-auc:0.859058\tvalidation_1-auc:0.839006\n",
      "[161]\tvalidation_0-auc:0.859102\tvalidation_1-auc:0.839001\n",
      "[162]\tvalidation_0-auc:0.859186\tvalidation_1-auc:0.838983\n",
      "[163]\tvalidation_0-auc:0.859323\tvalidation_1-auc:0.839044\n",
      "[164]\tvalidation_0-auc:0.859541\tvalidation_1-auc:0.839329\n",
      "[165]\tvalidation_0-auc:0.859680\tvalidation_1-auc:0.839322\n",
      "[166]\tvalidation_0-auc:0.859760\tvalidation_1-auc:0.839429\n",
      "[167]\tvalidation_0-auc:0.859807\tvalidation_1-auc:0.839386\n",
      "[168]\tvalidation_0-auc:0.859923\tvalidation_1-auc:0.839306\n",
      "[169]\tvalidation_0-auc:0.860016\tvalidation_1-auc:0.839256\n",
      "[170]\tvalidation_0-auc:0.860091\tvalidation_1-auc:0.839329\n",
      "[171]\tvalidation_0-auc:0.860143\tvalidation_1-auc:0.839328\n",
      "[172]\tvalidation_0-auc:0.860257\tvalidation_1-auc:0.839315\n",
      "[173]\tvalidation_0-auc:0.860337\tvalidation_1-auc:0.839385\n",
      "[174]\tvalidation_0-auc:0.860424\tvalidation_1-auc:0.839341\n",
      "[175]\tvalidation_0-auc:0.860495\tvalidation_1-auc:0.839377\n",
      "[176]\tvalidation_0-auc:0.860635\tvalidation_1-auc:0.839470\n",
      "[177]\tvalidation_0-auc:0.860699\tvalidation_1-auc:0.839480\n",
      "[178]\tvalidation_0-auc:0.860819\tvalidation_1-auc:0.839542\n",
      "[179]\tvalidation_0-auc:0.860935\tvalidation_1-auc:0.839630\n",
      "[180]\tvalidation_0-auc:0.861041\tvalidation_1-auc:0.839440\n",
      "[181]\tvalidation_0-auc:0.861122\tvalidation_1-auc:0.839531\n",
      "[182]\tvalidation_0-auc:0.861262\tvalidation_1-auc:0.839680\n",
      "[183]\tvalidation_0-auc:0.861347\tvalidation_1-auc:0.839585\n",
      "[184]\tvalidation_0-auc:0.861416\tvalidation_1-auc:0.839593\n",
      "[185]\tvalidation_0-auc:0.861458\tvalidation_1-auc:0.839551\n",
      "[186]\tvalidation_0-auc:0.861537\tvalidation_1-auc:0.839473\n",
      "[187]\tvalidation_0-auc:0.861599\tvalidation_1-auc:0.839469\n",
      "[188]\tvalidation_0-auc:0.861687\tvalidation_1-auc:0.839414\n",
      "[189]\tvalidation_0-auc:0.861732\tvalidation_1-auc:0.839399\n",
      "[190]\tvalidation_0-auc:0.861835\tvalidation_1-auc:0.839350\n",
      "[191]\tvalidation_0-auc:0.861939\tvalidation_1-auc:0.839387\n",
      "[192]\tvalidation_0-auc:0.862016\tvalidation_1-auc:0.839608\n",
      "[193]\tvalidation_0-auc:0.862135\tvalidation_1-auc:0.839604\n",
      "[194]\tvalidation_0-auc:0.862263\tvalidation_1-auc:0.839698\n",
      "[195]\tvalidation_0-auc:0.862337\tvalidation_1-auc:0.839737\n",
      "[196]\tvalidation_0-auc:0.862437\tvalidation_1-auc:0.839739\n",
      "[197]\tvalidation_0-auc:0.862494\tvalidation_1-auc:0.839713\n",
      "[198]\tvalidation_0-auc:0.862604\tvalidation_1-auc:0.839755\n",
      "[199]\tvalidation_0-auc:0.862662\tvalidation_1-auc:0.839721\n",
      "[200]\tvalidation_0-auc:0.862742\tvalidation_1-auc:0.839858\n",
      "[201]\tvalidation_0-auc:0.862845\tvalidation_1-auc:0.839734\n",
      "[202]\tvalidation_0-auc:0.862926\tvalidation_1-auc:0.839711\n",
      "[203]\tvalidation_0-auc:0.862971\tvalidation_1-auc:0.839691\n",
      "[204]\tvalidation_0-auc:0.863022\tvalidation_1-auc:0.839777\n",
      "[205]\tvalidation_0-auc:0.863037\tvalidation_1-auc:0.839675\n",
      "[206]\tvalidation_0-auc:0.863100\tvalidation_1-auc:0.839664\n",
      "[207]\tvalidation_0-auc:0.863183\tvalidation_1-auc:0.839657\n",
      "[208]\tvalidation_0-auc:0.863281\tvalidation_1-auc:0.839578\n",
      "[209]\tvalidation_0-auc:0.863411\tvalidation_1-auc:0.839448\n",
      "[210]\tvalidation_0-auc:0.863477\tvalidation_1-auc:0.839447\n",
      "[211]\tvalidation_0-auc:0.863552\tvalidation_1-auc:0.839468\n",
      "[212]\tvalidation_0-auc:0.863640\tvalidation_1-auc:0.839415\n",
      "[213]\tvalidation_0-auc:0.863690\tvalidation_1-auc:0.839410\n",
      "[214]\tvalidation_0-auc:0.863840\tvalidation_1-auc:0.839473\n",
      "[215]\tvalidation_0-auc:0.863953\tvalidation_1-auc:0.839490\n",
      "[216]\tvalidation_0-auc:0.864009\tvalidation_1-auc:0.839399\n",
      "[217]\tvalidation_0-auc:0.864099\tvalidation_1-auc:0.839471\n",
      "[218]\tvalidation_0-auc:0.864179\tvalidation_1-auc:0.839514\n",
      "[219]\tvalidation_0-auc:0.864293\tvalidation_1-auc:0.839550\n",
      "[220]\tvalidation_0-auc:0.864360\tvalidation_1-auc:0.839545\n",
      "[221]\tvalidation_0-auc:0.864445\tvalidation_1-auc:0.839593\n",
      "[222]\tvalidation_0-auc:0.864519\tvalidation_1-auc:0.839645\n",
      "[223]\tvalidation_0-auc:0.864575\tvalidation_1-auc:0.839701\n",
      "[224]\tvalidation_0-auc:0.864739\tvalidation_1-auc:0.839611\n",
      "[225]\tvalidation_0-auc:0.864778\tvalidation_1-auc:0.839559\n",
      "[226]\tvalidation_0-auc:0.864832\tvalidation_1-auc:0.839565\n",
      "[227]\tvalidation_0-auc:0.864903\tvalidation_1-auc:0.839522\n",
      "[228]\tvalidation_0-auc:0.864974\tvalidation_1-auc:0.839537\n",
      "[229]\tvalidation_0-auc:0.865017\tvalidation_1-auc:0.839580\n",
      "[230]\tvalidation_0-auc:0.865136\tvalidation_1-auc:0.839651\n",
      "[231]\tvalidation_0-auc:0.865221\tvalidation_1-auc:0.839537\n",
      "[232]\tvalidation_0-auc:0.865301\tvalidation_1-auc:0.839610\n",
      "[233]\tvalidation_0-auc:0.865418\tvalidation_1-auc:0.839530\n",
      "[234]\tvalidation_0-auc:0.865476\tvalidation_1-auc:0.839431\n",
      "[235]\tvalidation_0-auc:0.865551\tvalidation_1-auc:0.839419\n",
      "[236]\tvalidation_0-auc:0.865608\tvalidation_1-auc:0.839389\n",
      "[237]\tvalidation_0-auc:0.865632\tvalidation_1-auc:0.839351\n",
      "[238]\tvalidation_0-auc:0.865695\tvalidation_1-auc:0.839377\n",
      "[239]\tvalidation_0-auc:0.865739\tvalidation_1-auc:0.839299\n",
      "[240]\tvalidation_0-auc:0.865775\tvalidation_1-auc:0.839272\n",
      "[241]\tvalidation_0-auc:0.865811\tvalidation_1-auc:0.839262\n",
      "[242]\tvalidation_0-auc:0.865869\tvalidation_1-auc:0.839239\n",
      "[243]\tvalidation_0-auc:0.865933\tvalidation_1-auc:0.839198\n",
      "[244]\tvalidation_0-auc:0.866055\tvalidation_1-auc:0.839233\n",
      "[245]\tvalidation_0-auc:0.866097\tvalidation_1-auc:0.839250\n",
      "[246]\tvalidation_0-auc:0.866165\tvalidation_1-auc:0.839261\n",
      "[247]\tvalidation_0-auc:0.866257\tvalidation_1-auc:0.839410\n",
      "[248]\tvalidation_0-auc:0.866317\tvalidation_1-auc:0.839345\n",
      "[249]\tvalidation_0-auc:0.866428\tvalidation_1-auc:0.839311\n",
      "[250]\tvalidation_0-auc:0.866515\tvalidation_1-auc:0.839390\n",
      "Stopping. Best iteration:\n",
      "[200]\tvalidation_0-auc:0.862742\tvalidation_1-auc:0.839858\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=3, missing=None, n_estimators=256, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=0.0411987070619, seed=123, silent=True,\n",
       "       subsample=1.0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try using... eval_metric: mlogloss, merror, ndcg@n-\n",
    "est.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds=50, eval_metric='auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model for later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('models/my_xgb_3.pkl', 'wb') as f:\n",
    "    cPickle.dump(est, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load it again\n",
    "with open('models/my_xgb_2.pkl', 'rb') as f:\n",
    "    clf_loaded = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est_2 = clf_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit the data\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit with one-hot-encoded features\n",
    "est.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Fit with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=415, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [2, 32]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring=make_scorer(roc_auc_score), verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit data with random forest\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=32,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=415, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the best predictor\n",
    "est = reg.best_estimator_\n",
    "est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## predict classes\n",
    "ypred = est.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view the results, my_xgb_2\n",
    "print metrics.classification_report(y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98     73012\n",
      "          1       0.00      0.00      0.00      3008\n",
      "\n",
      "avg / total       0.92      0.96      0.94     76020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the results, my_xgb_2\n",
    "print metrics.classification_report(y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96     73012\n",
      "          1       0.35      0.90      0.50      3008\n",
      "\n",
      "avg / total       0.97      0.93      0.94     76020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the results, my_rf_1\n",
    "print metrics.classification_report(y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96753999461\n"
     ]
    }
   ],
   "source": [
    "## predict probabilities\n",
    "ypred = est.predict_proba(X)\n",
    "print metrics.roc_auc_score(y, ypred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 2)\n"
     ]
    }
   ],
   "source": [
    "## predict test, class probabilities\n",
    "ypred_submit = est.predict_proba(X_test_submit)\n",
    "print ypred_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.33448022e-01,   6.65520288e-02],\n",
       "       [  9.62528953e-01,   3.74710348e-02],\n",
       "       [  9.99925745e-01,   7.42562042e-05],\n",
       "       [  9.99568772e-01,   4.31227818e-04],\n",
       "       [  9.98117258e-01,   1.88275319e-03],\n",
       "       [  8.86325098e-01,   1.13674911e-01],\n",
       "       [  9.61121901e-01,   3.88780951e-02],\n",
       "       [  8.96974891e-01,   1.03025138e-01],\n",
       "       [  9.71420058e-01,   2.85799215e-02],\n",
       "       [  9.89302377e-01,   1.06976180e-02]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict using a second model and average the results\n",
    "ypred_2 = est_2.predict_proba(X_test_submit)\n",
    "ypred_avg = (.2 * ypred_submit) + (.8 * ypred_2)\n",
    "ypred_avg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate submission: stack ids and targets together into dataframe\n",
    "# old --> sub = pd.DataFrame(np.column_stack(id_test, ypred_submit[:,1])), columns=['ID', 'TARGET'])\n",
    "sub = pd.concat([id_test, pd.Series(ypred_submit[:,1], name='TARGET')], axis=1)\n",
    "# write dataframe to csv\n",
    "sub.to_csv('../submit/xgb_3_20160415.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Predict probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 2)\n"
     ]
    }
   ],
   "source": [
    "## predict class probabilities\n",
    "ypred_prob = est.predict_proba(X)\n",
    "print ypred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.896968</td>\n",
       "      <td>0.103032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963320</td>\n",
       "      <td>0.036680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.970958</td>\n",
       "      <td>0.029042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.868622</td>\n",
       "      <td>0.131378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.945749</td>\n",
       "      <td>0.054251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.990958</td>\n",
       "      <td>0.009042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944273</td>\n",
       "      <td>0.055727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.931341</td>\n",
       "      <td>0.068659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.393919</td>\n",
       "      <td>0.606081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.961911</td>\n",
       "      <td>0.038089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.907562</td>\n",
       "      <td>0.092438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   0.896968  0.103032\n",
       "1   0.963320  0.036680\n",
       "2   0.970958  0.029042\n",
       "3   0.868622  0.131378\n",
       "4   0.945749  0.054251\n",
       "5   0.990958  0.009042\n",
       "6   0.944273  0.055727\n",
       "7   0.931341  0.068659\n",
       "8   0.393919  0.606081\n",
       "9   0.961911  0.038089\n",
       "10  0.907562  0.092438"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ypred_prob)[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62096, 12)\n"
     ]
    }
   ],
   "source": [
    "## predict test, class probabilities\n",
    "ypred_submit = est.predict_proba(X_test_submit)\n",
    "print ypred_submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "iv. Tensorflow\n",
    "----------\n",
    "\n",
    "> **1-2 hidden layers **<br>\n",
    "> steps 5001, L2 reg .001, hidden 1024, rate (.5, 1000, .8), Test accuracy: **58.78**%<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x500, keep .9, rate (.05 adagrad), Test accuracy: **58.78**%<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x300, keep 1., rate (.01 adagrad), Test accuracy: **58.17**%<br>\n",
    "\n",
    "> **1-2 hidden layers, init low w, b**<br>\n",
    "> steps 5001, L2 reg .0002, hidden 1024x500, keep 1., rate (.1 adagrad), Test accuracy: **58.78**%<br>\n",
    "\n",
    "> **3 hidden layers **<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x300x50, rate (.01 adagrad), Test accuracy: **58.17**%<br>\n",
    "\n",
    "> **PCA 40 dims **<br>\n",
    "> steps 9001, L2 reg .001, hidden 1024x300x50, rate (.01 adagrad), Test accuracy: **58.17**%<br>\n",
    "\n",
    "> **107 features (del 'first_browser') **<br>\n",
    "> steps 5001, L2 reg .0002, hidden 1024x300x50, rate (.1 adagrad), Test accuracy: **58.04**%<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev=0.1):\n",
    "  initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, constant=0.):\n",
    "  initial = tf.constant(constant, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Build graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192639, 316)\n",
      "float32\n",
      "(10139, 316)\n",
      "(10673, 316)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "(192639, 12)\n",
      "(10139, 12)\n",
      "(10673, 12)\n",
      "(62096, 316)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_train.dtype\n",
    "print X_valid.shape\n",
    "print X_test.shape\n",
    "print y_train[:3]\n",
    "print y_train.shape\n",
    "print y_valid.shape\n",
    "print y_test.shape\n",
    "\n",
    "print X_test_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_L2 = 0.0002\n",
    "batch_size = 128\n",
    "num_hidden_1 = 1024\n",
    "#num_hidden_2 = 300\n",
    "#num_hidden_3 = 50\n",
    "num_features = X_train.shape[1]\n",
    "num_labels = 12\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, num_features))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(X_valid)\n",
    "  tf_test_dataset = tf.constant(X_test)\n",
    "  tf_test_submit = tf.constant(X_test_submit)\n",
    "  \n",
    "  # Variables.\n",
    "  w = weight_variable(shape=[num_features, num_hidden_1])\n",
    "  b = bias_variable(shape=[num_hidden_1])\n",
    "\n",
    "  #w2 = weight_variable(shape=[num_hidden_1, num_hidden_2])\n",
    "  #b2 = bias_variable(shape=[num_hidden_2])\n",
    "\n",
    "  #w3 = weight_variable(shape=[num_hidden_2, num_hidden_3])\n",
    "  #b3 = bias_variable(shape=[num_hidden_3])\n",
    "\n",
    "  w4 = weight_variable(shape=[num_hidden_1, num_labels])\n",
    "  b4 = bias_variable(shape=[num_labels])\n",
    "  \n",
    "  # Training computation.\n",
    "  def model(data):\n",
    "    h = tf.nn.relu(tf.matmul(data, w) + b)\n",
    "    ##Dropout\n",
    "    keep_prob = tf.constant(1.)\n",
    "    #h2 = tf.tanh(tf.matmul(h, w2) + b2)\n",
    "    #h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "    #h3 = tf.tanh(tf.matmul(h2, w3) + b3)\n",
    "    #h3_drop = tf.tanh(tf.matmul(h2_drop, w3) + b3)\n",
    "    #h3_drop = tf.nn.dropout(h3_drop, keep_prob)\n",
    "    h4 = tf.matmul(h, w4) + b4\n",
    "    return h4\n",
    "  \n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # L2 regularization for the fully connected parameters.\n",
    "  #regularizers = tf.nn.l2_loss(w) + tf.nn.l2_loss(w4)\n",
    "  # Add the regularization term to the loss.\n",
    "  #loss += reg_L2 * 0.5 * regularizers\n",
    "  \n",
    "  # Optimizer.\n",
    "  ## with learning rate decay\n",
    "  ##global_step = tf.Variable(0, trainable=False) # count the number of steps taken.\n",
    "  ##learning_rate = tf.train.exponential_decay(1., global_step, 500, 0.6, staircase=False)\n",
    "  ##optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  optimizer = tf.train.AdagradOptimizer(.01).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, test, and test submission data.\n",
    "  def predict(data):\n",
    "    h = tf.nn.relu(tf.matmul(data, w) + b)\n",
    "    #h2 = tf.tanh(tf.matmul(h, w2) + b2)\n",
    "    #h3 = tf.tanh(tf.matmul(h2, w3) + b3)\n",
    "    h4 = tf.matmul(h, w4) + b4\n",
    "    return h4\n",
    "  train_prediction = tf.nn.softmax(predict(tf_train_dataset))\n",
    "  valid_prediction = tf.nn.softmax(predict(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(predict(tf_test_dataset))\n",
    "\n",
    "  submit_prediction = tf.nn.softmax(predict(tf_test_submit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "============\n",
      "Minibatch loss at step 0 : 3.26455\n",
      "Minibatch accuracy: 2.34%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Test accuracy: 58.78%\n",
      "====================\n",
      "Minibatch loss at step 300 : 1.16833\n",
      "Minibatch accuracy: 58.59%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Minibatch loss at step 600 : 1.36942\n",
      "Minibatch accuracy: 64.06%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Minibatch loss at step 900 : 1.13909\n",
      "Minibatch accuracy: 57.81%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Test accuracy: 58.78%\n",
      "====================\n",
      "Minibatch loss at step 1200 : 1.11844\n",
      "Minibatch accuracy: 61.72%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n",
      "Minibatch loss at step 1500 : 1.03941\n",
      "Minibatch accuracy: 64.06%\n",
      "Validation accuracy: 58.53%\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-332-bc05c01609cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Initialized\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mstep_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Test accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mypred_submit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-332-bc05c01609cb>\u001b[0m in \u001b[0;36mstep_eval\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;31m#print global_step.eval(), learning_rate.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jjl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jjl/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 404\u001b[0;31m                                target_list)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "    \n",
    "def step_eval():\n",
    "  for step in xrange(num_steps):\n",
    "    offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
    "    batch_data = X_train[offset:(offset + batch_size), :]\n",
    "    batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 300 == 0):\n",
    "      #print global_step.eval(), learning_rate.eval()\n",
    "      print \"Minibatch loss at step\", step, \":\", l\n",
    "      print \"Minibatch accuracy: %.2f%%\" % accuracy(predictions, batch_labels)\n",
    "      accuracy_valid = accuracy(valid_prediction.eval(), y_valid)\n",
    "      print \"Validation accuracy: %.2f%%\" % accuracy_valid\n",
    "      print \"-\" * 20\n",
    "      if accuracy_valid > 92.:\n",
    "        print \"Halted!\"\n",
    "        return\n",
    "    if (step % 1000 == 0):\n",
    "      print \"Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), y_test)\n",
    "      print \"=\" * 20\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print \"Initialized\\n\", \"=\"*12\n",
    "  step_eval()\n",
    "  print \"Test accuracy: %.2f%%\" % accuracy(test_prediction.eval(), y_test)\n",
    "  ypred_submit = submit_prediction.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00275282  0.00670136  0.00510201  0.00973255  0.02230456  0.01001685\n",
      "   0.01413022  0.57495332  0.00390214  0.00101802  0.30211538  0.04727076]\n",
      " [ 0.00274651  0.00668118  0.00512046  0.00975334  0.02227283  0.01004198\n",
      "   0.01409889  0.57516688  0.00390226  0.00101752  0.30192763  0.04727058]\n",
      " [ 0.00273304  0.00665983  0.00510894  0.00972562  0.02229475  0.01000752\n",
      "   0.01408009  0.57545155  0.00389516  0.00101317  0.30179265  0.04723767]\n",
      " [ 0.00274596  0.00669436  0.00510876  0.00974156  0.02229444  0.01002662\n",
      "   0.01412156  0.57517922  0.0039057   0.00101715  0.30187249  0.04729211]\n",
      " [ 0.00274236  0.00668534  0.00511654  0.00977065  0.0222552   0.01004988\n",
      "   0.01410146  0.57546836  0.00390035  0.00101695  0.30169925  0.0471937 ]]\n",
      "[[ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]\n",
      " [ 9  0  8  2  1  3  5  6  4 11 10  7]]\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n",
      "['NDF', 'US', 'other', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'NL', 'AU', 'PT']\n"
     ]
    }
   ],
   "source": [
    "check = ypred_submit[2000:2004]\n",
    "print check\n",
    "print np.argsort(check)\n",
    "for i in xrange(len(check)):\n",
    "    print le.inverse_transform(np.argsort(check[i])[::-1]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999917877712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  9.78861744e-01,   6.74757347e-03,   4.51010295e-03,\n",
       "         2.61483665e-03,   1.98095652e-03,   1.66506037e-03,\n",
       "         1.53418838e-03,   6.61320886e-04,   3.38065198e-04,\n",
       "         1.94961323e-04,   1.45336585e-04,   1.21470520e-04,\n",
       "         1.04067974e-04,   7.31320630e-05,   5.74512220e-05,\n",
       "         4.52821950e-05,   3.51608873e-05,   2.81331481e-05,\n",
       "         2.43653284e-05,   2.38319003e-05,   2.21391741e-05,\n",
       "         1.95618464e-05,   1.76877680e-05,   1.65547070e-05,\n",
       "         1.60630892e-05,   1.33524260e-05,   1.29397120e-05,\n",
       "         1.18637233e-05,   1.07646724e-05,   9.90932673e-06])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30, copy=True, whiten=False)\n",
    "\n",
    "# fit the data\n",
    "pca.fit(df_all)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print sum(pca.explained_variance_ratio_)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert categoricals to int\n",
    "for i in convert_to_cat:\n",
    "    Xtrain.loc[:,i] = Xtrain[i].astype(int)\n",
    "    Xtest.loc[:,i] = Xtest[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge train and test users\n",
    "Xall = pd.concat((Xtrain, Xtest), axis=0, ignore_index=True)\n",
    "Xall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_data = pd.DataFrame(pca.transform(df_all))\n",
    "sns.set()\n",
    "sns.pairplot(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain_trans = pd.DataFrame(pca.transform(Xtrain))\n",
    "Xtest_trans = pd.DataFrame(pca.transform(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all = pd.concat((Xtrain_trans, ytrain), axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x=2, y=0, data=train_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
